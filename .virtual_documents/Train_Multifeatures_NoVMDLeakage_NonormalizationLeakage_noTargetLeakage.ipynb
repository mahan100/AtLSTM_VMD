





# Parameters
SEQ_LEN = 24  # past 24 hours for each sample
TARGET_COL = "OT"  # target variable: Oil Temperature
FEATURE_COLS = ["OT", "HUFL", "HULL", "MUFL", "MULL", "LUFL", "LULL"]
EPOCHS = 50
BATCH_SIZE = 32

# VMD parameters
DC = 0  # no DC part imposed
init = 1  # initialize omegas uniformly
tol = 1e-7
K = 4  # number of VMD modes (tuneable)
alpha = 1705  # VMD alpha (tuneable)
tau = 0.05805898025979961  # VMD tau

LSTM_UNITS = 128
DROPOUT = 0.2
LEARNING_RATE = 1e-2


import os
import random

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns
import tensorflow as tf
from sklearn.metrics import mean_absolute_error, mean_squared_error
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras import Model
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.layers import *
from tensorflow.keras.layers import (
    LSTM,
    Attention,
    Bidirectional,
    Concatenate,
    Dense,
    Dropout,
    Input,
    Lambda,
    Layer,
    LayerNormalization,
    MultiHeadAttention,
    RepeatVector,
    Reshape,
    Softmax,
)
from tensorflow.keras.losses import mse
from tensorflow.keras.models import Model, Sequential
from tensorflow.keras.optimizers import Adam
from vmdpy import VMD


save_dir = os.path.expanduser("~/Project/Nested_Attention_BiLSTM_VMD/data/raw")
os.makedirs(save_dir, exist_ok=True)
# Full file path
file_path = os.path.join(save_dir, "ETTh1.csv")
# Load it whenever needed
df = pd.read_csv(file_path)
print(df.head())
df.columns = df.columns.str.strip().str.replace("\ufeff", "")
print(df.columns)
# Ensure datetime type
df["date"] = pd.to_datetime(df["date"])
df.set_index("date", inplace=True)
data = df[[TARGET_COL]].values


# Visualize
plt.figure(figsize=(12, 4))
plt.plot(df.index, df["OT"], label="Oil Temperature (OT)")
plt.title("ETTh1 - Oil Temperature Time Series")
plt.xlabel("Date")
plt.ylabel("OT")
plt.legend()
plt.show()





# =====================================================
# Split Train / Test
# =====================================================
split_idx = int(len(df) * 0.8)

X = df[FEATURE_COLS].values
y = df[TARGET_COL].values.reshape(-1, 1)

X_train, X_test = X[:split_idx], X[split_idx:]
y_train, y_test = y[:split_idx], y[split_idx:]

# =====================================================
# Column indices
# =====================================================
ot_idx = FEATURE_COLS.index(TARGET_COL)
other_feature_indices = [i for i, c in enumerate(FEATURE_COLS) if c != TARGET_COL]

# =====================================================
# VMD + sequence creator (OT only)
# =====================================================
def create_sequences_ot_vmd_only(X, y, seq_len, alpha, tau, K, ot_idx, other_idxs):
    Xs, ys = [], []

    for i in range(len(X) - seq_len):
        seq_x = X[i : i + seq_len]  # (seq_len, num_features)
        seq_y = y[i + seq_len]

        # --- VMD on OT only ---
        ot_signal = seq_x[:, ot_idx]
        if alpha > 0 and K > 1:
            u, _, _ = VMD(ot_signal, alpha, tau, K, DC=0, init=1, tol=1e-7)
            ot_vmd = np.stack(u, axis=1)  # (seq_len, K)
        else:
            ot_vmd = ot_signal.reshape(seq_len, 1)

        # --- Other features (raw) ---
        other_feats = seq_x[:, other_idxs]

        # --- Concatenate ---
        seq_x_final = np.concatenate([ot_vmd, other_feats], axis=1)

        Xs.append(seq_x_final)
        ys.append(seq_y)

    return np.array(Xs), np.array(ys)


# =====================================================
# Create sequences (train / test)
# =====================================================
X_train_vmd_seq, y_train_vmd_seq = create_sequences_ot_vmd_only(
    X_train, y_train, SEQ_LEN, alpha, tau, K, ot_idx, other_feature_indices
)

X_test_vmd_seq, y_test_vmd_seq = create_sequences_ot_vmd_only(
    X_test, y_test, SEQ_LEN, alpha, tau, K, ot_idx, other_feature_indices
)

# =====================================================
# Scaling
# =====================================================
# Separate scalers for X (features) and Y (target)
scaler_x = MinMaxScaler()
scaler_y = MinMaxScaler()

# --- Prepare X ---
num_train, seq_len, feat_dim = X_train_vmd_seq.shape
num_test = X_test_vmd_seq.shape[0]
ot_vmd_dim = K
n_other = feat_dim - K

# Split OT-VMD and other features
X_train_ot_vmd = X_train_vmd_seq[:, :, :ot_vmd_dim].reshape(-1, ot_vmd_dim)
X_train_other = X_train_vmd_seq[:, :, ot_vmd_dim:].reshape(-1, n_other)

X_test_ot_vmd = X_test_vmd_seq[:, :, :ot_vmd_dim].reshape(-1, ot_vmd_dim)
X_test_other = X_test_vmd_seq[:, :, ot_vmd_dim:].reshape(-1, n_other)

# Fit scaler on TRAIN only
scaler_x.fit(np.concatenate([X_train_ot_vmd, X_train_other], axis=1))
scaler_y.fit(y_train_vmd_seq)

# Transform
X_train_vmd_scaled = scaler_x.transform(
    np.concatenate([X_train_ot_vmd, X_train_other], axis=1)
).reshape(num_train, seq_len, feat_dim)

X_test_vmd_scaled = scaler_x.transform(
    np.concatenate([X_test_ot_vmd, X_test_other], axis=1)
).reshape(num_test, seq_len, feat_dim)

y_train_vmd_scaled = scaler_y.transform(y_train_vmd_seq.reshape(-1, 1)).flatten()
y_test_vmd_scaled = scaler_y.transform(y_test_vmd_seq.reshape(-1, 1)).flatten()

# =====================================================
# Optional: inverse transform for evaluation
# =====================================================
y_test_vmd_true = scaler_y.inverse_transform(y_test_vmd_scaled.reshape(-1, 1)).flatten()

# =====================================================
# simple sequences without VMD
# =====================================================
x_scaler_simple = MinMaxScaler()
X_train_scaled = x_scaler_simple.fit_transform(X_train)
X_test_scaled = x_scaler_simple.transform(X_test)
y_scaler_simple = MinMaxScaler()
y_train_scaled = y_scaler_simple.fit_transform(y_train.reshape(-1, 1))
y_test_scaled = y_scaler_simple.transform(y_test.reshape(-1, 1))


def create_sequences_noVMD(X, y, seq_len):
    Xs, ys = [], []
    for i in range(len(X) - seq_len):
        Xs.append(X[i : i + seq_len])
        ys.append(y[i + seq_len])
    return np.array(Xs), np.array(ys)


X_train_simple, y_train_simple = create_sequences_noVMD(
    X_train_scaled, y_train_scaled, SEQ_LEN
)
X_test_simple, y_test_simple = create_sequences_noVMD(
    X_test_scaled, y_test_scaled, SEQ_LEN
)
y_test_simple_true = scaler_y.inverse_transform(y_test_simple.reshape(-1, 1)).flatten()
sum(y_test_vmd_true - y_test_simple_true)


diff = y_test_simple_true.squeeze() - y_test_vmd_true.squeeze()

plt.figure(figsize=(10, 4))
plt.plot(diff)
plt.title("Difference: y_test_simple_true ‚àí y_test_vmd_true")
plt.xlabel("Sample index")
plt.ylabel("Difference")
plt.grid(True)
plt.show()





# ===================================================
# PERFORMER ATTENTION
# ===================================================
class PerformerAttention(Layer):
    def __init__(self, num_heads, model_dim, kernel_eps=1e-6, dropout=0.1, **kwargs):
        super().__init__(**kwargs)
        self.num_heads = num_heads
        self.model_dim = model_dim
        self.kernel_eps = kernel_eps
        self.dropout = Dropout(dropout)
        self.head_dim = model_dim // num_heads
        assert model_dim % num_heads == 0, "model_dim must be divisible by num_heads"

    def build(self, input_shape):
        # Linear projections
        self.Wq = Dense(self.model_dim)
        self.Wk = Dense(self.model_dim)
        self.Wv = Dense(self.model_dim)
        self.Wo = Dense(self.model_dim)

        # Random Gaussian projection for FAVOR+
        self.proj = self.add_weight(
            shape=(self.head_dim, self.head_dim),
            initializer="random_normal",
            trainable=False,
            name="proj_matrix",
        )

    def kernel(self, x):
        # FAVOR+ kernel Œ¶(x)
        x_proj = tf.einsum("...nd,df->...nf", x, self.proj)
        return tf.nn.relu(x_proj) + self.kernel_eps

    def split_heads(self, x):
        B = tf.shape(x)[0]
        T = tf.shape(x)[1]
        x = tf.reshape(x, (B, T, self.num_heads, self.head_dim))
        return tf.transpose(x, [0, 2, 1, 3])  # (B, H, T, Dh)

    def merge_heads(self, x):
        B = tf.shape(x)[0]
        T = tf.shape(x)[2]
        x = tf.transpose(x, [0, 2, 1, 3])
        return tf.reshape(x, (B, T, self.model_dim))

    def call(self, x, training=False):
        Q, K, V = x  # all shape (B, T, model_dim)

        # Linear projections + split heads
        Q = self.split_heads(self.Wq(Q))
        K = self.split_heads(self.Wk(K))
        V = self.split_heads(self.Wv(V))

        # FAVOR+ kernel
        Q_phi = self.kernel(Q)  # (B, H, T, Dh)
        K_phi = self.kernel(K)

        # Compute KV and normalization
        KV = tf.einsum("bhnd,bhne->bhde", K_phi, V)  # (B,H,Dh,Dh)
        Z = 1.0 / (
            tf.einsum("bhnd,bhd->bhn", Q_phi, tf.reduce_sum(K_phi, axis=2)) + 1e-6
        )
        out = tf.einsum("bhnd,bhde,bhn->bhne", Q_phi, KV, Z)

        # Merge heads
        out = self.merge_heads(out)
        return self.Wo(out)


# ===================================================
# VAE SAMPLING LAYER
# ===================================================
class KLDivergenceLayer(tf.keras.layers.Layer):
    def call(self, inputs):
        mu, log_var = inputs
        kl = -0.5 * tf.reduce_mean(1 + log_var - tf.square(mu) - tf.exp(log_var))
        self.add_loss(kl)
        return inputs


class Sampling(tf.keras.layers.Layer):
    def call(self, inputs):
        mu, log_var = inputs
        eps = tf.random.normal(tf.shape(mu))
        return mu + tf.exp(0.5 * log_var) * eps


# =====================================================
# 2Ô∏è‚É£ Bahdanau-style Attention Layer
# =====================================================
class AttentionLayer_Bahdanau(Layer):
    def __init__(self, **kwargs):
        super(AttentionLayer_Bahdanau, self).__init__(**kwargs)

    def build(self, input_shape):
        self.W = self.add_weight(
            shape=(input_shape[-1], input_shape[-1]),
            initializer="glorot_uniform",
            trainable=True,
            name="att_weight",
        )
        self.b = self.add_weight(
            shape=(input_shape[-1],),
            initializer="zeros",
            trainable=True,
            name="att_bias",
        )
        self.u = self.add_weight(
            shape=(input_shape[-1],),
            initializer="glorot_uniform",
            trainable=True,
            name="context_vector",
        )
        super(AttentionLayer_Bahdanau, self).build(input_shape)

    def call(self, x):
        # x shape: (batch, time_steps, features)
        u_it = tf.tanh(
            tf.tensordot(x, self.W, axes=1) + self.b
        )  # (batch, time, features)
        a_it = tf.tensordot(u_it, self.u, axes=1)  # (batch, time)
        a_it = tf.nn.softmax(a_it, axis=1)  # (batch, time)
        a_it = tf.expand_dims(a_it, axis=-1)  # (batch, time, 1)
        weighted_output = x * a_it  # (batch, time, features)
        return tf.reduce_sum(weighted_output, axis=1)  # (batch, features)

    def compute_output_shape(self, input_shape):
        # output shape: (batch, features)
        return (input_shape[0], input_shape[2])


def build_attlstm_model(
    input_shape, lstm1_units=128, lstm2_units=64, dense_units=32, dropout=0.2, lr=1e-3
):
    inp = Input(shape=input_shape)

    # Encoder LSTM
    x = LSTM(lstm1_units, return_sequences=True)(inp)
    x = Dropout(dropout)(x)

    # Attention
    att_out = AttentionLayer_Bahdanau()(x)

    # Decoder LSTM
    x = Reshape((1, lstm1_units))(att_out)
    x = LSTM(lstm2_units, return_sequences=False)(x)
    x = Dropout(dropout)(x)

    # Dense layers
    x = Dense(dense_units, activation="relu")(x)
    out = Dense(1)(x)

    model = Model(inp, out)
    model.compile(optimizer=Adam(lr), loss="mse", metrics=["mae"])
    return model


# ========================================
# üìå     LSTM + Residual Connection + LayerNorm
# ========================================
class LSTM_residual_norm(Layer):
    def __init__(self, units, dropout=0.1, **kwargs):
        super(LSTM_residual_norm, self).__init__(**kwargs)
        self.units = units
        self.dropout_rate = dropout

        self.lstm = LSTM(units, return_sequences=True)
        self.dropout_layer = Dropout(dropout)
        self.norm = LayerNormalization()

    def build(self, input_shape):
        input_dim = input_shape[-1]  # <-- Detect feature count automatically

        # Projection for residual connection
        self.proj = Dense(self.units)  # input_dim ‚Üí units

        super().build(input_shape)

    def call(self, x):
        h = self.lstm(x)
        h = self.dropout_layer(h)

        h_res = self.proj(x)  # Now works for any feature dimension

        return self.norm(h + h_res)


# ========================================
# üìå  Attention(Bahdanau) + LSTM + Residual Connection + LayerNorm
# ========================================
def build_att_customlstm_model(
    input_shape, lstm1_units=128, lstm2_units=64, dense_units=32, dropout=0.2, lr=1e-3
):
    inp = Input(shape=input_shape)

    # Encoder LSTM
    x = LSTM_residual_norm(lstm1_units)(inp)
    x = Dropout(dropout)(x)

    # Attention
    att_out = AttentionLayer_Bahdanau()(x)

    # Decoder LSTM
    x = Reshape((1, lstm1_units))(att_out)
    x = LSTM_residual_norm(lstm2_units)(x)
    x = Dropout(dropout)(x)

    # Dense layers
    x = Dense(dense_units, activation="relu")(x)
    out = Dense(1)(x)

    model = Model(inp, out)
    model.compile(optimizer=Adam(lr), loss="mse", metrics=["mae"])
    return model


# =========================================================
# üìå  Custom Luong Attention
# score = h_t ¬∑ W ¬∑ h_s  (dot-product)
# =========================================================
class LuongAttention(Layer):
    def __init__(self, units):
        super(LuongAttention, self).__init__()
        self.Wq = Dense(units)
        self.Wv = Dense(units)

    def call(self, query, value, mask=None):
        # Project both ‚Üí SAME dimension
        q = self.Wq(query)  # (B, T, units)
        v = self.Wv(value)  # (B, T, units)

        # Dot product score
        score = tf.matmul(q, v, transpose_b=True)  # (B, T, T)

        if mask is not None:
            score += mask * -1e9

        # Use tf.nn.softmax (Keras-safe)
        attn_weights = tf.nn.softmax(score, axis=-1)  # (B, T, T)
        context = tf.matmul(attn_weights, v)  # (B, T, units)

        return context


# =========================================================
# üìå  Temporal Attention (per timestep)
# =========================================================
class TemporalAttention(Layer):
    def __init__(self, units, **kwargs):
        super().__init__(**kwargs)
        self.units = units

    def build(self, input_shape):
        # input_shape = (batch, timesteps, features)
        d = input_shape[-1]

        self.Wt = Dense(self.units, activation="tanh")
        self.vt = Dense(1)

    def call(self, x):
        # score shape -> (batch, timesteps, units)
        h = self.Wt(x)

        # score shape -> (batch, timesteps, 1)
        score = self.vt(h)

        # attention weights
        alpha = tf.nn.softmax(score, axis=1)

        # weighted sum (batch, timesteps, features) -> (batch, features)
        context = tf.reduce_sum(alpha * x, axis=1)

        return context


def build_Tattlstm_model(
    input_shape, lstm1_units=128, lstm2_units=64, dense_units=32, dropout=0.2, lr=1e-3
):

    inp = Input(shape=input_shape)

    # Encoder LSTM
    x = LSTM(lstm1_units, return_sequences=True)(inp)
    x = Dropout(dropout)(x)

    # Temporal Attention
    att_out = TemporalAttention(units=lstm1_units)(x)

    # Decoder LSTM - convert context vector to sequence again
    x = Reshape((1, lstm1_units))(att_out)
    x = LSTM(lstm2_units, return_sequences=False)(x)
    x = Dropout(dropout)(x)

    # Dense layers
    x = Dense(dense_units, activation="relu")(x)
    out = Dense(1)(x)

    model = Model(inp, out)
    model.compile(optimizer=Adam(learning_rate=lr), loss="mse", metrics=["mae"])
    return model


# =========================================================
# üìå  Cross-Attention (Query from XLSTM, Key/Value from VMD input)
# =========================================================
class CrossAttention(Layer):
    def __init__(self, num_heads=4, key_dim=32):
        super().__init__()
        self.mha = MultiHeadAttention(num_heads=num_heads, key_dim=key_dim)

    def call(self, query, context, mask=None):
        return self.mha(query=query, value=context, key=context, attention_mask=mask)


# =========================================================
# üìå  Causal Masking (prevent future leakage)
# =========================================================
def causal_mask(seq_len):
    mask = tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)
    return mask[None, None, :, :]


# =========================================================
# üìå  InceptionTime block (1D, residual, multi-scale)
# =========================================================
def inception_time_block(x, filters=64, bottleneck=32):
    shortcut = x

    # Bottleneck (1x1 conv)
    if x.shape[-1] > bottleneck:
        x = Conv1D(bottleneck, kernel_size=1, padding="same", activation="relu")(x)

    # Parallel convolutions (same temporal length)
    conv1 = Conv1D(filters, 3, padding="same", activation="relu")(x)
    conv2 = Conv1D(filters, 5, padding="same", activation="relu")(x)
    conv3 = Conv1D(filters, 7, padding="same", activation="relu")(x)

    # üîë Pooling MUST preserve length + project channels
    pool = MaxPooling1D(pool_size=3, strides=1, padding="same")(x)  # üî• critical
    pool = Conv1D(filters, 1, padding="same", activation="relu")(pool)

    # Concatenate (now shapes match)
    x = Concatenate()([conv1, conv2, conv3, pool])
    x = BatchNormalization()(x)

    # Residual connection
    shortcut = Conv1D(x.shape[-1], 1, padding="same")(shortcut)
    x = Add()([x, shortcut])
    x = Activation("relu")(x)

    return x


# =========================================================
# üìå   TCN++ block (dilated, residual)
# =========================================================
def tcn_block(x, filters=64, kernel_size=3, dilation=1, dropout=0.1):
    shortcut = x

    x = Conv1D(
        filters, kernel_size, dilation_rate=dilation, padding="same", activation="relu"
    )(x)
    x = Dropout(dropout)(x)

    x = Conv1D(
        filters, kernel_size, dilation_rate=dilation, padding="same", activation="relu"
    )(x)

    shortcut = Conv1D(filters, 1, padding="same")(shortcut)
    x = Add()([x, shortcut])
    x = LayerNormalization()(x)

    return x


# =========================================================
# üìå  TFT Multi-Head Temporal self-Attention Layer (Keras)
#     this is a valid implementation of the temporal self-attention block inspired by the TFT paper:
#     Multi-head scaled dot-product attention
#     Decoder state as query
#     Encoder outputs as key/value
#     Layer norm + residual
#     Optional causal masking
#     It is simplified (no gating via GRN or VSN), but the attention math is correct and aligned with Transformer/TFT definitions.
# =========================================================
class TFTTemporalAttention(tf.keras.layers.Layer):
    def __init__(self, num_heads, model_dim, dropout_rate=0.1, **kwargs):
        super().__init__(**kwargs)
        self.num_heads = num_heads
        self.model_dim = model_dim
        self.dropout_rate = dropout_rate

        assert model_dim % num_heads == 0
        self.depth = model_dim // num_heads

        self.Wq = Dense(model_dim)
        self.Wk = Dense(model_dim)
        self.Wv = Dense(model_dim)

        self.dense = Dense(model_dim)
        self.dropout = Dropout(dropout_rate)

    def split_heads(self, x):
        # (B, T, D) ‚Üí (B, H, T, D/H)
        batch_size = tf.shape(x)[0]
        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))
        return tf.transpose(x, perm=[0, 2, 1, 3])

    def build(self, input_shape):
        # input_shape = (B, T, D)
        self.Wq.build(input_shape)
        self.Wk.build(input_shape)
        self.Wv.build(input_shape)
        self.dense.build(input_shape)
        super().build(input_shape)

    def call(self, x, training=None):
        q = self.split_heads(self.Wq(x))
        k = self.split_heads(self.Wk(x))
        v = self.split_heads(self.Wv(x))

        scale = tf.math.sqrt(tf.cast(self.depth, tf.float32))
        scores = tf.matmul(q, k, transpose_b=True) / scale
        weights = tf.nn.softmax(scores, axis=-1)

        weights = self.dropout(weights, training=training)
        att = tf.matmul(weights, v)

        att = tf.transpose(att, perm=[0, 2, 1, 3])
        batch_size = tf.shape(att)[0]
        att = tf.reshape(att, (batch_size, -1, self.model_dim))

        return self.dense(att)


def build_TFTattlstm_model(
    input_shape,
    lstm1_units=100,
    lstm2_units=100,
    dense_units=32,
    model_dim=64,
    dropout=0.1,
):

    # Input
    encoder_inputs = Input(shape=input_shape)

    # Encoder
    enc_out = LSTM(lstm1_units, return_sequences=True)(encoder_inputs)
    enc_out = Dropout(dropout)(enc_out)
    enc_out = Dense(model_dim)(enc_out)
    enc_out = LayerNormalization()(enc_out)

    # Bahdanau Attention on encoder
    bahdanau_att_enc = AttentionLayer_Bahdanau()(enc_out)

    # Decoder
    dec_input = Lambda(lambda x: tf.expand_dims(x, axis=1))(bahdanau_att_enc)
    dec_out = LSTM(lstm2_units, return_sequences=True)(dec_input)
    dec_out = Dropout(dropout)(dec_out)
    dec_out = Dense(model_dim)(dec_out)
    dec_out = LayerNormalization()(dec_out)

    # Bahdanau Attention on decoder
    bahdanau_att_dec = AttentionLayer_Bahdanau()(dec_out)

    # Final Dense Output
    x = Dense(dense_units, activation="relu")(bahdanau_att_dec)
    output = Dense(1)(x)

    # Build model
    model = Model(inputs=encoder_inputs, outputs=output, name="TFT_Att_LSTM_Bahdanau")
    model.compile(optimizer="adam", loss="mse", metrics=["mae"])
    return model


def build_TFTattlstm_model2(
    input_shape,
    lstm1_units=100,
    lstm2_units=100,
    dense_units=32,
    num_heads=8,
    model_dim=64,
    dropout=0.1,
):

    # -------------------------
    # 0. Input
    # -------------------------
    input_group = Input(shape=input_shape)

    # -------------------------
    # 1. Encoder LSTM
    # -------------------------
    group1 = LSTM(lstm1_units, return_sequences=True)(input_group)
    group1 = Dropout(dropout)(group1)

    # -------------------------
    # 1b. Bahdanau Attention applied to encoder
    # -------------------------
    bahdanau_att_group1 = AttentionLayer_Bahdanau()(group1)
    bahdanau_att_group1 = Lambda(lambda x: tf.expand_dims(x, axis=1))(
        bahdanau_att_group1
    )

    # -------------------------
    # 2. Decoder LSTM
    # -------------------------
    group2 = LSTM(lstm1_units, return_sequences=True)(input_group)
    group2 = Dropout(dropout)(group2)

    # Bahdanau attention over decoder
    bahdanau_att_group2 = AttentionLayer_Bahdanau()(group2)
    bahdanau_att_group2 = Lambda(lambda x: tf.expand_dims(x, axis=1))(
        bahdanau_att_group2
    )

    # -------------------------
    # 3. TFT Multi-Head Attention Stack
    # -------------------------
    att_layer = TFTTemporalAttention(num_heads=num_heads, model_dim=model_dim)
    att_out = att_layer([bahdanau_att_group1, bahdanau_att_group2])

    # -------------------------
    # 4. Dense output
    # -------------------------
    x = Bidirectional(LSTM(dense_units))(att_out)
    output = Dense(1)(x)

    # -------------------------
    # 5. Model compile
    # -------------------------
    model = Model(input_group, output)
    model.compile(loss="mse", optimizer="adam", metrics=["mae"])

    return model


def build_TFTattlstm_model3(
    input_shape=(24, 8),
    lstm1_units=100,
    dense_units=32,
    num_heads=8,
    model_dim=64,
    dropout=0.1,
):

    # -------------------------
    # 0. Input
    # -------------------------
    input_group = Input(shape=input_shape)  # (24, 8)

    # -------------------------
    # **Split input: group1 = first 4 features, group2 = next 4**
    # -------------------------
    group1_input = Lambda(lambda x: x[:, :, :6])(input_group)  # (24, 4)
    group2_input = Lambda(lambda x: x[:, :, 6:])(input_group)  # (24, 4)
    # -------------------------
    # 1. Encoder LSTM for Group 1
    # -------------------------
    group1 = LSTM(lstm1_units, return_sequences=True)(group1_input)
    group1 = Dropout(dropout)(group1)

    bahdanau_att_group1 = AttentionLayer_Bahdanau()(group1)
    bahdanau_att_group1 = Lambda(lambda x: tf.expand_dims(x, axis=1))(
        bahdanau_att_group1
    )
    # -------------------------
    # 2. Encoder LSTM for Group 2
    # -------------------------
    group2 = LSTM(lstm1_units, return_sequences=True)(group2_input)
    group2 = Dropout(dropout)(group2)

    bahdanau_att_group2 = AttentionLayer_Bahdanau()(group2)
    bahdanau_att_group2 = Lambda(lambda x: tf.expand_dims(x, axis=1))(
        bahdanau_att_group2
    )
    # -------------------------
    # 3. TFT Multi-Head Temporal Attention
    # -------------------------
    att_layer = TFTTemporalAttention(num_heads=num_heads, model_dim=model_dim)
    att_out = att_layer([bahdanau_att_group1, bahdanau_att_group2])
    # -------------------------
    # 4. Dense Output
    # -------------------------
    output = Dense(1)(att_out)
    # -------------------------
    # 5. Compile Model
    # -------------------------
    model = Model(inputs=input_group, outputs=output)
    model.compile(loss="mse", optimizer="adam", metrics=["mae"])

    return model


# ============================
# BUILD Performer attlstm MODEL WITH cross attention
# ============================


def build_TFTattlstm_model4(
    input_shape=(24, 8),
    lstm1_units=100,
    dense_units=32,
    num_heads=8,
    model_dim=64,
    dropout=0.1,
):

    # -------------------------
    # 0. Input
    # -------------------------
    input_group = Input(shape=input_shape)  # (24, 8)

    # -------------------------
    # Split input
    # -------------------------
    group1_input = Lambda(lambda x: x[:, :, :6])(input_group)
    group2_input = Lambda(lambda x: x[:, :, 6:])(input_group)

    # -------------------------
    # 1. Encoder LSTM for Group 1
    # -------------------------
    group1 = LSTM(lstm1_units, return_sequences=True)(group1_input)
    group1 = Dropout(dropout)(group1)
    bahdanau_att_group1 = AttentionLayer_Bahdanau()(group1)
    bahdanau_att_group1 = Lambda(lambda x: tf.expand_dims(x, axis=1))(
        bahdanau_att_group1
    )

    # -------------------------
    # 2. Encoder LSTM for Group 2
    # -------------------------
    group2 = LSTM(lstm1_units, return_sequences=True)(group2_input)
    group2 = Dropout(dropout)(group2)
    bahdanau_att_group2 = AttentionLayer_Bahdanau()(group2)
    bahdanau_att_group2 = Lambda(lambda x: tf.expand_dims(x, axis=1))(
        bahdanau_att_group2
    )

    # -------------------------
    # 3. Cross Attention
    # -------------------------
    cross = CrossAttention(num_heads=num_heads, key_dim=model_dim)

    g1_to_g2 = cross(query=bahdanau_att_group1, context=bahdanau_att_group2)
    g2_to_g1 = cross(query=bahdanau_att_group2, context=bahdanau_att_group1)
    cross_out = Concatenate(axis=1)(
        [g1_to_g2, g2_to_g1]
    )  # shape: (batch, 2, model_dim)

    # -------------------------
    # 4. Multi-Head Attention (replaces Performer)
    # -------------------------
    mha = MultiHeadAttention(num_heads=num_heads, key_dim=model_dim)
    att_out = mha(query=cross_out, value=cross_out, key=cross_out)
    att_out = Dropout(dropout)(att_out)
    att_out = LayerNormalization(epsilon=1e-6)(att_out)

    # -------------------------
    # 5. LSTM + Output
    # -------------------------
    x = Bidirectional(LSTM(dense_units))(att_out)
    output = Dense(1)(x)

    # -------------------------
    # 6. Model
    # -------------------------
    model = Model(inputs=input_group, outputs=output)
    model.compile(loss="mse", optimizer="adam", metrics=["mae"])

    return model


# ============================
# BUILD TFTattlstm MODEL WITH VAE
# ============================
def build_TFTattlstm_model5(
    input_shape=(24, 8),
    lstm1_units=100,
    dense_units=32,
    latent_dim=16,
    num_heads=8,
    model_dim=64,
    dropout=0.1,
):

    # -------------------------
    # 0. Input
    # -------------------------
    input_group = Input(shape=input_shape)

    # -------------------------
    # 1. Split Inputs
    # -------------------------
    group1_input = Lambda(lambda x: x[:, :, :6])(input_group)
    group2_input = Lambda(lambda x: x[:, :, 6:])(input_group)

    # -------------------------
    # 2. LSTM + Bahdanau Group1
    # -------------------------
    group1 = LSTM(lstm1_units, return_sequences=True)(group1_input)
    group1 = Dropout(dropout)(group1)
    bahdanau1 = AttentionLayer_Bahdanau()(group1)
    bahdanau1 = Lambda(lambda x: tf.expand_dims(x, 1))(bahdanau1)

    # -------------------------
    # 3. LSTM + Bahdanau Group2
    # -------------------------
    group2 = LSTM(lstm1_units, return_sequences=True)(group2_input)
    group2 = Dropout(dropout)(group2)
    bahdanau2 = AttentionLayer_Bahdanau()(group2)
    bahdanau2 = Lambda(lambda x: tf.expand_dims(x, 1))(bahdanau2)

    # -------------------------
    # 4. CONCAT Bahdanau outputs
    # -------------------------
    combined = Concatenate(axis=1)([bahdanau1, bahdanau2])  # (batch, 2, features)

    # -------------------------
    # 5. Flatten for VAE Encoder
    # -------------------------
    flat = Flatten()(combined)
    flat_dim = flat.shape[-1]  # static

    # -------------------------
    # 6. VAE Encoder
    # -------------------------
    mu = Dense(latent_dim)(flat)
    log_var = Dense(latent_dim)(flat)

    # Apply KL divergence correctly
    mu, log_var = KLDivergenceLayer()([mu, log_var])

    # Sampling
    z = Sampling()([mu, log_var])

    # -------------------------
    # 7. VAE Decoder
    # -------------------------
    decoder_hidden = Dense(64, activation="relu")(z)
    decoder_out = Dense(flat_dim, activation="linear")(decoder_hidden)

    decoder_out_reshaped = Reshape((2, flat_dim // 2))(decoder_out)

    # -------------------------
    # 8. TFT Multi-Head Temporal Attention
    # -------------------------
    att_layer = TFTTemporalAttention(num_heads=num_heads, model_dim=model_dim)
    att_out = att_layer([decoder_out_reshaped, decoder_out_reshaped])

    # -------------------------
    # 9. LSTM + Dense Output
    # -------------------------
    x = Bidirectional(LSTM(dense_units))(att_out)
    output = Dense(1)(x)

    # -------------------------
    # 10. Final Model
    # -------------------------
    model = Model(inputs=input_group, outputs=output)

    model.compile(optimizer="adam", loss="mse", metrics=["mae"])

    return model


# ============================
# BUILD TFTattlstm MODEL WITH PERFORMER
# ============================
def build_TFTattlstm_model6(
    input_shape=(24, 8),
    lstm1_units=64,
    dense_units=8,
    num_heads=8,
    model_dim=64,
    dropout=0.1,
):

    # 0. Input
    input_group = Input(shape=input_shape)  # (seq_len, features)

    # 1. Split input
    group1_input = Lambda(lambda x: x[:, :, :6])(input_group)
    group2_input = Lambda(lambda x: x[:, :, 6:])(input_group)

    # 2. LSTM for group1
    group1 = LSTM(lstm1_units, return_sequences=True)(group1_input)
    group1 = Dropout(dropout)(group1)

    # 3. LSTM for group2
    group2 = LSTM(lstm1_units, return_sequences=True)(group2_input)
    group2 = Dropout(dropout)(group2)

    # 4. Performer Attention on each group
    performer_att_group1 = PerformerAttention(num_heads=num_heads, model_dim=model_dim)(
        [group1, group1, group1]
    )
    performer_att_group2 = PerformerAttention(num_heads=num_heads, model_dim=model_dim)(
        [group2, group2, group2]
    )

    # Take last time step for each group
    performer_att_group1 = Lambda(lambda x: x[:, -1, :], name="group1_last_step")(
        performer_att_group1
    )
    performer_att_group2 = Lambda(lambda x: x[:, -1, :], name="group2_last_step")(
        performer_att_group2
    )

    # 5. Concatenate
    cross_out = Concatenate()([performer_att_group1, performer_att_group2])

    # 6. Dense + Output
    x = Dense(dense_units, activation="relu")(cross_out)
    output = Dense(1)(x)

    # 7. Compile
    model = Model(inputs=input_group, outputs=output)
    model.compile(loss="mse", optimizer="adam", metrics=["mae"])

    return model


# ============================
# BUILD TFTattlstm MODEL WITH PERFORMER and BAHDANAU
# ============================
def build_TFTattlstm_model7(
    input_shape=(24, 8),
    lstm1_units=64,
    dense_units=8,
    num_heads=8,
    model_dim=64,
    dropout=0.1,
):

    # 0. Input
    input_group = Input(shape=input_shape)  # (seq_len, features)

    # 2. LSTM for group1
    group1 = LSTM(lstm1_units, return_sequences=True)(input_group)
    group1 = Dropout(dropout)(group1)

    # 3. LSTM for group2
    group2 = LSTM(lstm1_units, return_sequences=True)(input_group)
    group2 = Dropout(dropout)(group2)

    # 4. Bahdanau Attention for group1
    bahdanau_att_group1 = AttentionLayer_Bahdanau()(group1)
    # Expand dims to match Performer output shape
    bahdanau_att_group1 = Lambda(
        lambda x: tf.expand_dims(x, axis=1), name="group1_bahdanau_expand"
    )(bahdanau_att_group1)
    # Take last step
    bahdanau_att_group1 = Lambda(lambda x: x[:, -1, :], name="group1_last_step")(
        bahdanau_att_group1
    )

    # 5. Performer Attention for group2
    performer_att_group2 = PerformerAttention(num_heads=num_heads, model_dim=model_dim)(
        [group2, group2, group2]
    )
    performer_att_group2 = Lambda(lambda x: x[:, -1, :], name="group2_last_step")(
        performer_att_group2
    )

    # 6. Concatenate
    cross_out = Concatenate()([bahdanau_att_group1, performer_att_group2])

    # 7. Dense + Output
    x = Dense(dense_units, activation="relu")(cross_out)
    output = Dense(1)(x)

    # 8. Compile
    model = Model(inputs=input_group, outputs=output)
    model.compile(loss="mae", optimizer="adam", metrics=["mse"])

    return model


def build_TFTattlstm_model8(
    input_shape=(24, 8),
    lstm1_units=64,
    cnn_filters=64,
    cnn_kernel=3,
    dense_units=8,
    num_heads=8,
    model_dim=64,
    dropout=0.1,
):

    # =====================================================
    # 0. Input
    # =====================================================
    input_group = Input(shape=input_shape)  # (seq_len, features)

    # =====================================================
    # 1. Group 1: LSTM ‚Üí CNN ‚Üí Bahdanau Attention
    # =====================================================
    group1 = LSTM(lstm1_units, return_sequences=True)(input_group)
    group1 = Dropout(dropout)(group1)

    group1 = Conv1D(
        filters=cnn_filters, kernel_size=cnn_kernel, padding="same", activation="relu"
    )(group1)
    group1 = BatchNormalization()(group1)

    bahdanau_att_group1 = AttentionLayer_Bahdanau()(group1)
    bahdanau_att_group1 = Lambda(
        lambda x: tf.expand_dims(x, axis=1), name="group1_bahdanau_expand"
    )(bahdanau_att_group1)
    bahdanau_att_group1 = Lambda(lambda x: x[:, -1, :], name="group1_last_step")(
        bahdanau_att_group1
    )

    # =====================================================
    # 2. Group 2: LSTM ‚Üí CNN ‚Üí Performer Attention
    # =====================================================
    group2 = LSTM(lstm1_units, return_sequences=True)(input_group)
    group2 = Dropout(dropout)(group2)

    group2 = Conv1D(
        filters=cnn_filters, kernel_size=cnn_kernel, padding="same", activation="relu"
    )(group2)
    group2 = BatchNormalization()(group2)

    performer_att_group2 = PerformerAttention(num_heads=num_heads, model_dim=model_dim)(
        [group2, group2, group2]
    )

    performer_att_group2 = Lambda(lambda x: x[:, -1, :], name="group2_last_step")(
        performer_att_group2
    )

    # =====================================================
    # 3. Cross Fusion
    # =====================================================
    cross_out = Concatenate()([bahdanau_att_group1, performer_att_group2])

    # =====================================================
    # 4. Dense + Output
    # =====================================================
    x = Dense(dense_units, activation="relu")(cross_out)
    output = Dense(1)(x)

    # =====================================================
    # 5. Compile
    # =====================================================
    model = Model(inputs=input_group, outputs=output)
    model.compile(loss="mae", optimizer="adam", metrics=["mse"])

    return model


def build_TFTattlstm_model9(
    input_shape=(24, 8),
    lstm1_units=64,
    cnn_filters=64,
    cnn_kernel=3,
    dense_units=8,
    num_heads=8,
    model_dim=64,
    dropout=0.1,
):

    # =====================================================
    # 0. Input
    # =====================================================
    input_group = Input(shape=input_shape)  # (seq_len, features)

    # =====================================================
    # 1. Group 1: LSTM ‚Üí Bahdanau Attention (NO CNN)
    # =====================================================
    group1 = LSTM(lstm1_units, return_sequences=True)(input_group)
    group1 = Dropout(dropout)(group1)

    bahdanau_att_group1 = AttentionLayer_Bahdanau()(group1)
    bahdanau_att_group1 = Lambda(
        lambda x: tf.expand_dims(x, axis=1), name="group1_bahdanau_expand"
    )(bahdanau_att_group1)
    bahdanau_att_group1 = Lambda(lambda x: x[:, -1, :], name="group1_last_step")(
        bahdanau_att_group1
    )

    # =====================================================
    # 2. Group 2: LSTM ‚Üí CNN ‚Üí Performer Attention
    # =====================================================
    group2 = LSTM(lstm1_units, return_sequences=True)(input_group)
    group2 = Dropout(dropout)(group2)

    # üîπ CNN ONLY here
    group2 = Conv1D(
        filters=cnn_filters,
        kernel_size=cnn_kernel,
        padding="same",
        activation="relu",
        name="group2_cnn",
    )(group2)

    performer_att_group2 = PerformerAttention(num_heads=num_heads, model_dim=model_dim)(
        [group2, group2, group2]
    )

    performer_att_group2 = Lambda(lambda x: x[:, -1, :], name="group2_last_step")(
        performer_att_group2
    )

    # =====================================================
    # 3. Fusion
    # =====================================================
    cross_out = Concatenate()([bahdanau_att_group1, performer_att_group2])

    # =====================================================
    # 4. Dense + Output
    # =====================================================
    x = Dense(dense_units, activation="relu")(cross_out)
    output = Dense(1)(x)

    # =====================================================
    # 5. Compile
    # =====================================================
    model = Model(inputs=input_group, outputs=output)
    model.compile(loss="mae", optimizer="adam", metrics=["mse"])

    return model


def build_TFTattlstm_model10(
    input_shape,
    lstm1_units=100,
    cnn_filters=64,
    cnn_kernel=3,
    dense_units=32,
    num_heads=8,
    model_dim=64,
    dropout=0.1,
):

    # =====================================================
    # 0. Inputs
    # =====================================================
    encoder_inputs = Input(shape=input_shape)

    # =====================================================
    # 1. Encoder: LSTM ‚Üí CNN ‚Üí Bahdanau Attention
    # =====================================================
    enc_out = LSTM(lstm1_units, return_sequences=True)(encoder_inputs)
    enc_out = Dropout(dropout)(enc_out)

    # üîπ CNN for encoder group
    enc_out = Conv1D(
        filters=cnn_filters,
        kernel_size=cnn_kernel,
        padding="same",
        activation="relu",
        name="encoder_cnn",
    )(enc_out)

    enc_out = Dense(model_dim)(enc_out)
    enc_out = LayerNormalization()(enc_out)

    bahdanau_att_enc = AttentionLayer_Bahdanau()(enc_out)
    bahdanau_att_enc = Lambda(lambda x: tf.expand_dims(x, axis=1), name="enc_expand")(
        bahdanau_att_enc
    )

    # =====================================================
    # 2. Decoder: LSTM ‚Üí CNN ‚Üí Bahdanau Attention
    # =====================================================
    dec_out = LSTM(lstm1_units, return_sequences=True)(bahdanau_att_enc)
    dec_out = Dropout(dropout)(dec_out)

    # üîπ CNN for decoder group
    dec_out = Conv1D(
        filters=cnn_filters,
        kernel_size=cnn_kernel,
        padding="same",
        activation="relu",
        name="decoder_cnn",
    )(dec_out)

    dec_out = Dense(model_dim)(dec_out)
    dec_out = LayerNormalization()(dec_out)

    bahdanau_att_dec = AttentionLayer_Bahdanau()(dec_out)

    # =====================================================
    # 3. TFT Multi-Head Temporal Attention
    # =====================================================
    att_layer = TFTTemporalAttention(num_heads=num_heads, model_dim=model_dim)

    att_out = att_layer([bahdanau_att_enc, bahdanau_att_dec])

    # =====================================================
    # 4. Output head
    # =====================================================
    x = Bidirectional(LSTM(dense_units))(att_out)

    output = Dense(1)(x)

    # =====================================================
    # 5. Compile
    # =====================================================
    model = Model(encoder_inputs, output)
    model.compile(loss="mae", optimizer="adam", metrics=["mse"])

    return (
        model,
        encoder_inputs,
        enc_out,
        bahdanau_att_enc,
        dec_out,
        bahdanau_att_dec,
        att_out,
    )


def build_TFTattlstm_model11(
    input_shape,
    lstm1_units=100,
    cnn_filters=64,
    dense_units=32,
    num_heads=8,
    model_dim=64,
    dropout=0.1,
    feature_extractor="inception",  # "inception" or "tcn"
):

    # =====================================================
    # 0. Inputs
    # =====================================================
    encoder_inputs = Input(shape=input_shape)

    # =====================================================
    # 1. Encoder: LSTM ‚Üí InceptionTime / TCN++ ‚Üí Bahdanau
    # =====================================================
    enc_out = LSTM(lstm1_units, return_sequences=True)(encoder_inputs)
    enc_out = Dropout(dropout)(enc_out)

    if feature_extractor == "inception":
        enc_out = inception_time_block(enc_out, filters=cnn_filters)
    else:
        enc_out = tcn_block(enc_out, filters=cnn_filters, dilation=1)
        enc_out = tcn_block(enc_out, filters=cnn_filters, dilation=2)

    enc_out = Dense(model_dim)(enc_out)
    enc_out = LayerNormalization()(enc_out)

    bahdanau_att_enc = AttentionLayer_Bahdanau()(enc_out)
    bahdanau_att_enc = Lambda(lambda x: tf.expand_dims(x, axis=1))(bahdanau_att_enc)

    # =====================================================
    # 2. Decoder: LSTM ‚Üí InceptionTime / TCN++ ‚Üí Bahdanau
    # =====================================================
    dec_out = LSTM(lstm1_units, return_sequences=True)(bahdanau_att_enc)
    dec_out = Dropout(dropout)(dec_out)

    if feature_extractor == "inception":
        dec_out = inception_time_block(dec_out, filters=cnn_filters)
    else:
        dec_out = tcn_block(dec_out, filters=cnn_filters, dilation=1)

    dec_out = Dense(model_dim)(dec_out)
    dec_out = LayerNormalization()(dec_out)

    bahdanau_att_dec = AttentionLayer_Bahdanau()(dec_out)

    # =====================================================
    # 3. TFT Multi-Head Temporal Attention
    # =====================================================
    att_out = TFTTemporalAttention(num_heads=num_heads, model_dim=model_dim)(
        [bahdanau_att_enc, bahdanau_att_dec]
    )

    # =====================================================
    # 4. Output head
    # =====================================================
    x = Bidirectional(LSTM(dense_units))(att_out)
    output = Dense(1)(x)

    # =====================================================
    # 5. Compile
    # =====================================================
    model = Model(encoder_inputs, output)
    model.compile(optimizer="adam", loss="mae", metrics=["mse"])

    return model


def build_TFTattlstm_model12(
    input_shape,
    lstm1_units=64,
    lstm2_units=64,
    cnn_filters=128,
    cnn_kernel=3,
    dense_units=32,
    model_dim=64,
    dropout=0.1,
    num_heads=4,
):
    # -------------------------
    # 0. Input
    # -------------------------
    encoder_inputs = Input(shape=input_shape)  # (seq_len, features)

    # -------------------------
    # 1. BLOCK1
    # -------------------------
    block1 = LSTM(lstm1_units, return_sequences=True)(encoder_inputs)
    block1 = Dropout(dropout)(block1)
    block1 = LayerNormalization()(block1)
    block1 = Conv1D(
        filters=cnn_filters, kernel_size=cnn_kernel, padding="same", activation="relu"
    )(block1)
    block1 = Dense(model_dim)(block1)
    block1 = LayerNormalization()(block1)
    att_out_block1 = AttentionLayer_Bahdanau()(block1)  # (batch, model_dim)
    att_out_block1 = Lambda(lambda x: tf.expand_dims(x, axis=1))(
        att_out_block1
    )  # (batch, 1, model_dim)

    # -------------------------
    # 2. BLOCK2
    # -------------------------
    block2 = LSTM(lstm2_units, return_sequences=True)(block1)
    block2 = Dropout(dropout)(block2)
    block2 = LayerNormalization()(block2)
    block2 = Conv1D(
        filters=cnn_filters, kernel_size=cnn_kernel, padding="same", activation="relu"
    )(block2)
    block2 = Dense(model_dim)(block2)
    block2 = LayerNormalization()(block2)
    att_out_block2 = AttentionLayer_Bahdanau()(block2)  # (batch, model_dim)
    att_out_block2 = Lambda(lambda x: tf.expand_dims(x, axis=1))(
        att_out_block2
    )  # (batch, 1, model_dim)

    # -------------------------
    # 2. BLOCK3
    # -------------------------
    block3 = LSTM(lstm1_units, return_sequences=True)(encoder_inputs)
    block3 = Dropout(dropout)(block3)
    block3 = LayerNormalization()(block3)
    block3 = Conv1D(
        filters=cnn_filters, kernel_size=cnn_kernel, padding="same", activation="relu"
    )(block3)
    block3 = Dense(model_dim)(block3)
    block3 = LayerNormalization()(block3)
    att_out_block3 = AttentionLayer_Bahdanau()(block3)  # (batch, model_dim)
    att_out_block3 = Lambda(lambda x: tf.expand_dims(x, axis=1))(
        att_out_block3
    )  # (batch, 1, model_dim)

    # -------------------------
    # 3. Concatenate attention outputs
    # -------------------------
    fused_att = Concatenate(axis=-1)(
        [att_out_block1, att_out_block2, att_out_block3]
    )  # (batch, 1, 2*model_dim)
    fused_att_flat = Lambda(lambda x: tf.squeeze(x, axis=1))(
        fused_att
    )  # (batch, 2*model_dim)
    # -------------------------
    # 4. Dense output head
    # -------------------------
    x = Dense(dense_units, activation="relu")(fused_att_flat)
    output = Dense(1, name="forecast")(x)

    # -------------------------
    # 5. Build model
    # -------------------------
    model = Model(
        inputs=encoder_inputs, outputs=output, name="TFT_Att_LSTM_Conv_Bahdanau"
    )
    model.compile(optimizer="adam", loss="mae", metrics=["mse"])

    return model, encoder_inputs, block1, block2, att_out




def build_TFTattlstm_model13(
    input_shape,
    lstm1_units=64,
    lstm2_units=64,
    cnn_filters=128,
    cnn_kernel=3,
    dense_units=32,
    model_dim=64,
    dropout=0.1,
    num_heads=4,
):
    # --------------------------------------------------
    # Row-wise division layer
    # --------------------------------------------------
    def rowwise_division(x, eps=1e-8):
        first_row = x[:, :1, :]
        prev_rows = x[:, :-1, :]
        curr_rows = x[:, 1:, :]
        divided = curr_rows / (prev_rows + eps)
        return tf.concat([first_row, divided], axis=1)

    # --------------------------------------------------
    # Input
    # --------------------------------------------------
    inputs = Input(shape=input_shape, name="model_input")

    # --------------------------------------------------
    # 1st & 2nd order temporal gradients
    # --------------------------------------------------
    grad1 = Lambda(rowwise_division, name="rowwise_division_1")(inputs)
    grad2 = Lambda(rowwise_division, name="rowwise_division_2")(grad1)

    # --------------------------------------------------
    # BLOCK 1: LSTM + CNN (from grad1)
    # --------------------------------------------------
    block1 = LSTM(lstm1_units, return_sequences=True, name="lstm_block1")(grad1)
    block1 = Dropout(dropout)(block1)
    block1 = LayerNormalization()(block1)
    

    block1 = Conv1D(
        filters=cnn_filters,
        kernel_size=cnn_kernel,
        padding="same",
        activation="relu",
        name="conv_block1"
    )(block1)

    # --------------------------------------------------
    # BLOCK 2: LSTM + CNN (from grad2)
    # --------------------------------------------------
    block2 = LSTM(lstm2_units, return_sequences=True, name="lstm_block2")(grad2)
    block2 = Dropout(dropout)(block2)
    block2 = LayerNormalization()(block2)


    block2 = Conv1D(
        filters=cnn_filters,
        kernel_size=cnn_kernel,
        padding="same",
        activation="relu",
        name="conv_block2"
    )(block2)

    # --------------------------------------------------
    # Encoder-Decoder BLOCK
    # --------------------------------------------------
    # Encoder
    enc_out = LSTM(lstm1_units, return_sequences=True)(inputs)
    enc_out = Dropout(dropout)(enc_out)
    enc_out = Dense(model_dim)(enc_out)
    enc_out = LayerNormalization()(enc_out)

    # Bahdanau Attention on encoder
    bahdanau_att_enc = AttentionLayer_Bahdanau()(enc_out)

    # Decoder
    dec_input = Lambda(lambda x: tf.expand_dims(x, axis=1))(bahdanau_att_enc)
    dec_out = LSTM(lstm2_units, return_sequences=True)(dec_input)
    dec_out = Dropout(dropout)(dec_out)
    dec_out = Dense(model_dim)(dec_out)
    dec_out = LayerNormalization()(dec_out)

    # Bahdanau Attention on decoder
    bahdanau_att_dec = AttentionLayer_Bahdanau()(dec_out)
    bahdanau_att_dec_expanded = Lambda(
    lambda x: tf.repeat(tf.expand_dims(x, axis=1), repeats=SEQ_LEN, axis=1),
    name="bahdanau_att_dec_expanded"
    )(bahdanau_att_dec)

    # --------------------------------------------------
    # Concatenate LSTM outputs along feature axis
    # --------------------------------------------------
    att_input = Concatenate(axis=-1, name="att_concat")([block1, block2, bahdanau_att_dec_expanded])
    
    # Project concatenated features to model_dim
    att_proj = Dense(model_dim, activation=None, name="att_projection")(att_input)
    # --------------------------------------------------
    # Apply attention
    # ------------------------------------------------  
    
    
    att_out = TFTTemporalAttention(
        num_heads=num_heads,
        model_dim=model_dim,
        name="tft_temporal_attention"
    )(att_proj)

    # --------------------------------------------------
    # Reduce to last timestep
    # --------------------------------------------------
    att_out = Lambda(lambda x: x[:, -1, :], name="att_last_step")(att_out)

    # --------------------------------------------------
    # Dense head
    # --------------------------------------------------
    x = Dense(dense_units, activation="relu", name="dense_head")(att_out)
    output = Dense(1, name="forecast")(x)

    # --------------------------------------------------
    # Build and compile model
    # --------------------------------------------------
    optimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)
    model = Model(inputs=inputs, outputs=output, name="TFT_Att_LSTM_Conv")
    model.compile(optimizer="adam", loss="mae", metrics=["mse"])

    # --------------------------------------------------
    # Return model + intermediate tensors
    # --------------------------------------------------
    return model, grad2, block1, block2, att_out






model_build_attlstm_model = build_attlstm_model(
    input_shape=(SEQ_LEN, X_train_vmd_scaled.shape[2]),
    lstm1_units=132,
    lstm2_units=132,
    dense_units=64,
)
model_build_attlstm_model.summary()

history_attlstm_vmd = model_build_attlstm_model.fit(
    X_train_vmd_scaled,
    y_train_vmd_scaled,
    validation_data=(X_test_vmd_scaled, y_test_vmd_scaled),
    epochs=EPOCHS,
    batch_size=BATCH_SIZE,
    verbose=1,
)

# Predict and inverse-transform
y_pred_attlstm_vmd_scaled = model_build_attlstm_model.predict(X_test_vmd_scaled)
y_pred_attlstm_vmd_true = scaler_y.inverse_transform(y_pred_attlstm_vmd_scaled)

# =====================================================
# 8Ô∏è‚É£ Visualization
# =====================================================
plt.figure(figsize=(8, 4))
plt.plot(history_attlstm_vmd.history["loss"], label="Train Loss")
plt.plot(history_attlstm_vmd.history["val_loss"], label="Val Loss")
plt.title("Training & Validation Loss (ATT-LSTM + VMD)")
plt.legend()
plt.grid(True)
plt.show()

plt.figure(figsize=(12, 5))
plt.plot(y_test_vmd_true, label="True OT", color="black", linewidth=1)
plt.plot(y_pred_attlstm_vmd_true, label="Predicted OT", color="yellow", alpha=0.8)
plt.title("True vs Predicted OT (Optimized ATT-LSTM + VMD)")
plt.xlabel("Time Steps")
plt.ylabel("OT Value")
plt.legend()
plt.grid(True)
plt.show()

plt.figure(figsize=(10, 4))
residuals = y_test_vmd_true.squeeze() - y_pred_attlstm_vmd_true.squeeze()
plt.plot(residuals, color="purple")
plt.title("Residuals (True - Predicted)")
plt.grid(True)
plt.show()

res = y_test_vmd_true.squeeze() - y_pred_attlstm_vmd_true.squeeze()
area_total_attlstm_vmd = np.trapezoid(np.abs(res))
print("Total Area =", area_total_attlstm_vmd)
area_positive_attlstm_vmd = np.trapezoid(np.clip(res, 0, None))
area_negative_attlstm_vmd = np.trapezoid(np.clip(res, None, 0))
print("Area + =", area_positive_attlstm_vmd)
print("Area - =", area_negative_attlstm_vmd)





model_build_Tattlstm_model = build_Tattlstm_model(
    input_shape=(SEQ_LEN, X_train_vmd_scaled.shape[2]),
    lstm1_units=132,
    lstm2_units=132,
    dense_units=64,
)
model_build_Tattlstm_model.summary()

history_Tattlstm_vmd = model_build_Tattlstm_model.fit(
    X_train_vmd_scaled,
    y_train_vmd_scaled,
    validation_data=(X_test_vmd_scaled, y_test_vmd_scaled),
    epochs=EPOCHS,
    batch_size=BATCH_SIZE,
    verbose=1,
)

# Predict and inverse-transform
y_pred_Tattlstm_vmd_scaled = model_build_Tattlstm_model.predict(X_test_vmd_scaled)
y_pred_Tattlstm_vmd_true = scaler_y.inverse_transform(y_pred_Tattlstm_vmd_scaled)

# =====================================================
# 8Ô∏è‚É£ Visualization
# =====================================================
plt.figure(figsize=(8, 4))
plt.plot(history_Tattlstm_vmd.history["loss"], label="Train Loss")
plt.plot(history_Tattlstm_vmd.history["val_loss"], label="Val Loss")
plt.title("Training & Validation Loss (Temporary ATT-LSTM + VMD)")
plt.legend()
plt.grid(True)
plt.show()

plt.figure(figsize=(12, 5))
plt.plot(y_test_vmd_true, label="True OT", color="green", linewidth=1)
plt.plot(y_pred_Tattlstm_vmd_true, label="Predicted OT", color="yellow", alpha=0.8)
plt.title("True vs Predicted OT (Temporary ATT-LSTM + VMD)")
plt.xlabel("Time Steps")
plt.ylabel("OT Value")
plt.legend()
plt.grid(True)
plt.show()

plt.figure(figsize=(10, 4))
residuals = y_test_vmd_true.squeeze() - y_pred_Tattlstm_vmd_true.squeeze()
plt.plot(residuals, color="purple")
plt.title("Residuals (True - Predicted)")
plt.grid(True)
plt.show()

res = y_test_vmd_true.squeeze() - y_pred_Tattlstm_vmd_true.squeeze()
area_total_Tattlstm_vmd = np.trapezoid(np.abs(res))
print("Total Area =", area_total_Tattlstm_vmd)
area_positive_Tattlstm_vmd = np.trapezoid(np.clip(res, 0, None))
area_negative_Tattlstm_vmd = np.trapezoid(np.clip(res, None, 0))
print("Area + =", area_positive_Tattlstm_vmd)
print("Area - =", area_negative_Tattlstm_vmd)





model_build_TFTattlstm_model = build_TFTattlstm_model(
    input_shape=(SEQ_LEN, X_train_vmd_scaled.shape[2]),
    lstm1_units=128,
    lstm2_units=128,
    dense_units=16,
    model_dim=64,
    dropout=0.1,
)

model_build_TFTattlstm_model.summary()

history_TFTattlstm_vmd = model_build_TFTattlstm_model.fit(
    X_train_vmd_scaled,
    y_train_vmd_scaled,
    validation_data=(X_test_vmd_scaled, y_test_vmd_scaled),
    epochs=EPOCHS,
    batch_size=BATCH_SIZE,
    verbose=1,
)

# Predict and inverse-transform
y_pred_TFTattlstm_vmd_scaled = model_build_TFTattlstm_model.predict(X_test_vmd_scaled)
# Flatten to 2D: (num_samples*time_steps, 1)
y_pred_flat = y_pred_TFTattlstm_vmd_scaled.reshape(-1, 1)
# Inverse transform
y_pred_TFTattlstm_vmd_true = scaler_y.inverse_transform(y_pred_flat)

# Optional: reshape back to (num_samples, time_steps)
y_pred_TFTattlstm_vmd_true = y_pred_TFTattlstm_vmd_true.reshape(
    y_pred_TFTattlstm_vmd_scaled.shape[0], y_pred_TFTattlstm_vmd_scaled.shape[1]
)
# =====================================================
# 8Ô∏è‚É£ Visualization
# =====================================================
plt.figure(figsize=(8, 4))
plt.plot(history_TFTattlstm_vmd.history["loss"], label="Train Loss")
plt.plot(history_TFTattlstm_vmd.history["val_loss"], label="Val Loss")
plt.title("Training & Validation Loss (TFT ATT-LSTM + VMD)")
plt.legend()
plt.grid(True)
plt.show()

plt.figure(figsize=(12, 5))
plt.plot(y_test_vmd_true, label="True OT", color="black", linewidth=1)
plt.plot(y_pred_TFTattlstm_vmd_true, label="Predicted OT", color="red", alpha=0.8)
plt.title("True vs Predicted OT (TFT ATT-LSTM + VMD)")
plt.xlabel("Time Steps")
plt.ylabel("OT Value")
plt.legend()
plt.grid(True)
plt.show()

plt.figure(figsize=(10, 4))
residuals = y_test_vmd_true.squeeze() - y_pred_TFTattlstm_vmd_true.squeeze()
plt.plot(residuals, color="purple")
plt.title("Residuals (True - Predicted)")
plt.grid(True)
plt.show()


res = y_test_vmd_true.squeeze() - y_pred_TFTattlstm_vmd_true.squeeze()
area_total_TFTattlstm_vmd = np.trapezoid(np.abs(res))
print("Total Area =", area_total_TFTattlstm_vmd)
area_positive_TFTattlstm_vmd = np.trapezoid(np.clip(res, 0, None))
area_negative_TFTattlstm_vmd = np.trapezoid(np.clip(res, None, 0))
print("Area + =", area_positive_TFTattlstm_vmd)
print("Area - =", area_negative_TFTattlstm_vmd)


model_build_TFTattlstm_model = build_TFTattlstm_model2(
    input_shape=(SEQ_LEN, X_train_vmd_scaled.shape[2]),
    lstm1_units=128,
    lstm2_units=128,
    dense_units=16,
    num_heads=8,
    model_dim=64,
    dropout=0.1,
)

model_build_TFTattlstm_model.summary()

history_TFTattlstm_vmd = model_build_TFTattlstm_model.fit(
    X_train_vmd_scaled,
    y_train_vmd_scaled,
    validation_data=(X_test_vmd_scaled, y_test_vmd_scaled),
    epochs=EPOCHS,
    batch_size=BATCH_SIZE,
    verbose=1,
)

# Predict and inverse-transform
y_pred_TFTattlstm_vmd_scaled = model_build_TFTattlstm_model.predict(X_test_vmd_scaled)
# Flatten to 2D: (num_samples*time_steps, 1)
y_pred_flat = y_pred_TFTattlstm_vmd_scaled.reshape(-1, 1)
# Inverse transform
y_pred_TFTattlstm_vmd_true = scaler_y.inverse_transform(y_pred_flat)

# Optional: reshape back to (num_samples, time_steps)
y_pred_TFTattlstm_vmd_true = y_pred_TFTattlstm_vmd_true.reshape(
    y_pred_TFTattlstm_vmd_scaled.shape[0], y_pred_TFTattlstm_vmd_scaled.shape[1]
)
# =====================================================
# 8Ô∏è‚É£ Visualization
# =====================================================
plt.figure(figsize=(8, 4))
plt.plot(history_TFTattlstm_vmd.history["loss"], label="Train Loss")
plt.plot(history_TFTattlstm_vmd.history["val_loss"], label="Val Loss")
plt.title("Training & Validation Loss (TFT ATT-LSTM + VMD)")
plt.legend()
plt.grid(True)
plt.show()

plt.figure(figsize=(12, 5))
plt.plot(y_test_vmd_true, label="True OT", color="black", linewidth=1)
plt.plot(y_pred_TFTattlstm_vmd_true, label="Predicted OT", color="red", alpha=0.8)
plt.title("True vs Predicted OT (TFT ATT-LSTM + VMD)")
plt.xlabel("Time Steps")
plt.ylabel("OT Value")
plt.legend()
plt.grid(True)
plt.show()

plt.figure(figsize=(10, 4))
residuals = y_test_vmd_true.squeeze() - y_pred_TFTattlstm_vmd_true.squeeze()
plt.plot(residuals, color="purple")
plt.title("Residuals (True - Predicted)")
plt.grid(True)
plt.show()


res = y_test_vmd_true.squeeze() - y_pred_TFTattlstm_vmd_true.squeeze()
area_total_TFTattlstm_vmd = np.trapezoid(np.abs(res))
print("Total Area =", area_total_TFTattlstm_vmd)
area_positive_TFTattlstm_vmd = np.trapezoid(np.clip(res, 0, None))
area_negative_TFTattlstm_vmd = np.trapezoid(np.clip(res, None, 0))
print("Area + =", area_positive_TFTattlstm_vmd)
print("Area - =", area_negative_TFTattlstm_vmd)


model_build_TFTattlstm_model = build_TFTattlstm_model3(
    input_shape=(SEQ_LEN, X_train_vmd_scaled.shape[2]),
    lstm1_units=64,
    dense_units=4,
    num_heads=64,
    model_dim=256,
    dropout=0.1,
)

model_build_TFTattlstm_model.summary()

history_TFTattlstm_vmd = model_build_TFTattlstm_model.fit(
    X_train_vmd_scaled,
    y_train_vmd_scaled,
    validation_data=(X_test_vmd_scaled, y_test_vmd_scaled),
    epochs=EPOCHS,
    batch_size=BATCH_SIZE,
    verbose=1,
)

# Predict and inverse-transform
y_pred_TFTattlstm_vmd_scaled = model_build_TFTattlstm_model.predict(X_test_vmd_scaled)
# Flatten to 2D: (num_samples*time_steps, 1)
y_pred_flat = y_pred_TFTattlstm_vmd_scaled.reshape(-1, 1)
# Inverse transform
y_pred_TFTattlstm_vmd_true = scaler_y.inverse_transform(y_pred_flat)

# Optional: reshape back to (num_samples, time_steps)
y_pred_TFTattlstm_vmd_true = y_pred_TFTattlstm_vmd_true.reshape(
    y_pred_TFTattlstm_vmd_scaled.shape[0], y_pred_TFTattlstm_vmd_scaled.shape[1]
)
# =====================================================
# 8Ô∏è‚É£ Visualization
# =====================================================
plt.figure(figsize=(8, 4))
plt.plot(history_TFTattlstm_vmd.history["loss"], label="Train Loss")
plt.plot(history_TFTattlstm_vmd.history["val_loss"], label="Val Loss")
plt.title("Training & Validation Loss (TFT ATT-LSTM + VMD)")
plt.legend()
plt.grid(True)
plt.show()

plt.figure(figsize=(12, 5))
plt.plot(y_test_vmd_true, label="True OT", color="black", linewidth=1)
plt.plot(y_pred_TFTattlstm_vmd_true, label="Predicted OT", color="red", alpha=0.8)
plt.title("True vs Predicted OT (TFT ATT-LSTM + VMD)")
plt.xlabel("Time Steps")
plt.ylabel("OT Value")
plt.legend()
plt.grid(True)
plt.show()

plt.figure(figsize=(10, 4))
residuals = y_test_vmd_true.squeeze() - y_pred_TFTattlstm_vmd_true.squeeze()
plt.plot(residuals, color="purple")
plt.title("Residuals (True - Predicted)")
plt.grid(True)
plt.show()


res = y_test_vmd_true.squeeze() - y_pred_TFTattlstm_vmd_true.squeeze()
area_total_TFTattlstm_vmd = np.trapezoid(np.abs(res))
print("Total Area =", area_total_TFTattlstm_vmd)
area_positive_TFTattlstm_vmd = np.trapezoid(np.clip(res, 0, None))
area_negative_TFTattlstm_vmd = np.trapezoid(np.clip(res, None, 0))
print("Area + =", area_positive_TFTattlstm_vmd)
print("Area - =", area_negative_TFTattlstm_vmd)


model_build_TFTattlstm_model = build_TFTattlstm_model4(
    input_shape=(SEQ_LEN, X_train_vmd_scaled.shape[2]),
    lstm1_units=32,
    dense_units=4,
    num_heads=8,
    model_dim=64,
    dropout=0.1,
)

model_build_TFTattlstm_model.summary()

history_TFTattlstm_vmd = model_build_TFTattlstm_model.fit(
    X_train_vmd_scaled,
    y_train_vmd_scaled,
    validation_data=(X_test_vmd_scaled, y_test_vmd_scaled),
    epochs=EPOCHS,
    batch_size=BATCH_SIZE,
    verbose=1,
)

# Predict and inverse-transform
y_pred_TFTattlstm_vmd_scaled = model_build_TFTattlstm_model.predict(X_test_vmd_scaled)
# Flatten to 2D: (num_samples*time_steps, 1)
y_pred_flat = y_pred_TFTattlstm_vmd_scaled.reshape(-1, 1)
# Inverse transform
y_pred_TFTattlstm_vmd_true = scaler_y.inverse_transform(y_pred_flat)

# Optional: reshape back to (num_samples, time_steps)
y_pred_TFTattlstm_vmd_true = y_pred_TFTattlstm_vmd_true.reshape(
    y_pred_TFTattlstm_vmd_scaled.shape[0], y_pred_TFTattlstm_vmd_scaled.shape[1]
)
# =====================================================
# 8Ô∏è‚É£ Visualization
# =====================================================
plt.figure(figsize=(8, 4))
plt.plot(history_TFTattlstm_vmd.history["loss"], label="Train Loss")
plt.plot(history_TFTattlstm_vmd.history["val_loss"], label="Val Loss")
plt.title("Training & Validation Loss (TFT ATT-LSTM + VMD)")
plt.legend()
plt.grid(True)
plt.show()

plt.figure(figsize=(12, 5))
plt.plot(y_test_vmd_true, label="True OT", color="black", linewidth=1)
plt.plot(y_pred_TFTattlstm_vmd_true, label="Predicted OT", color="red", alpha=0.8)
plt.title("True vs Predicted OT (TFT ATT-LSTM + VMD)")
plt.xlabel("Time Steps")
plt.ylabel("OT Value")
plt.legend()
plt.grid(True)
plt.show()

plt.figure(figsize=(10, 4))
residuals = y_test_vmd_true.squeeze() - y_pred_TFTattlstm_vmd_true.squeeze()
plt.plot(residuals, color="purple")
plt.title("Residuals (True - Predicted)")
plt.grid(True)
plt.show()


res = y_test_vmd_true.squeeze() - y_pred_TFTattlstm_vmd_true.squeeze()
area_total_TFTattlstm_vmd = np.trapezoid(np.abs(res))
print("Total Area =", area_total_TFTattlstm_vmd)
area_positive_TFTattlstm_vmd = np.trapezoid(np.clip(res, 0, None))
area_negative_TFTattlstm_vmd = np.trapezoid(np.clip(res, None, 0))
print("Area + =", area_positive_TFTattlstm_vmd)
print("Area - =", area_negative_TFTattlstm_vmd)


model_build_TFTattlstm_model = build_TFTattlstm_model5(
    input_shape=(SEQ_LEN, X_train_vmd_scaled.shape[2]),
    lstm1_units=64,
    dense_units=8,
    num_heads=8,
    model_dim=256,
    dropout=0.1,
)

model_build_TFTattlstm_model.summary()

history_TFTattlstm_vmd = model_build_TFTattlstm_model.fit(
    X_train_vmd_scaled,
    y_train_vmd_scaled,
    validation_data=(X_test_vmd_scaled, y_test_vmd_scaled),
    epochs=EPOCHS,
    batch_size=BATCH_SIZE,
    verbose=1,
)

# Predict and inverse-transform
y_pred_TFTattlstm_vmd_scaled = model_build_TFTattlstm_model.predict(X_test_vmd_scaled)
# Flatten to 2D: (num_samples*time_steps, 1)
y_pred_flat = y_pred_TFTattlstm_vmd_scaled.reshape(-1, 1)
# Inverse transform
y_pred_TFTattlstm_vmd_true = scaler_y.inverse_transform(y_pred_flat)

# Optional: reshape back to (num_samples, time_steps)
y_pred_TFTattlstm_vmd_true = y_pred_TFTattlstm_vmd_true.reshape(
    y_pred_TFTattlstm_vmd_scaled.shape[0], y_pred_TFTattlstm_vmd_scaled.shape[1]
)
# =====================================================
# 8Ô∏è‚É£ Visualization
# =====================================================
plt.figure(figsize=(8, 4))
plt.plot(history_TFTattlstm_vmd.history["loss"], label="Train Loss")
plt.plot(history_TFTattlstm_vmd.history["val_loss"], label="Val Loss")
plt.title("Training & Validation Loss (TFT ATT-LSTM + VMD)")
plt.legend()
plt.grid(True)
plt.show()

plt.figure(figsize=(12, 5))
plt.plot(y_test_vmd_true, label="True OT", color="black", linewidth=1)
plt.plot(y_pred_TFTattlstm_vmd_true, label="Predicted OT", color="red", alpha=0.8)
plt.title("True vs Predicted OT (TFT ATT-LSTM + VMD)")
plt.xlabel("Time Steps")
plt.ylabel("OT Value")
plt.legend()
plt.grid(True)
plt.show()

plt.figure(figsize=(10, 4))
residuals = y_test_vmd_true.squeeze() - y_pred_TFTattlstm_vmd_true.squeeze()
plt.plot(residuals, color="purple")
plt.title("Residuals (True - Predicted)")
plt.grid(True)
plt.show()


res = y_test_vmd_true.squeeze() - y_pred_TFTattlstm_vmd_true.squeeze()
area_total_TFTattlstm_vmd = np.trapezoid(np.abs(res))
print("Total Area =", area_total_TFTattlstm_vmd)
area_positive_TFTattlstm_vmd = np.trapezoid(np.clip(res, 0, None))
area_negative_TFTattlstm_vmd = np.trapezoid(np.clip(res, None, 0))
print("Area + =", area_positive_TFTattlstm_vmd)
print("Area - =", area_negative_TFTattlstm_vmd)


model_build_TFTattlstm_model = build_TFTattlstm_model6(
    input_shape=(SEQ_LEN, X_train_vmd_scaled.shape[2]),
    lstm1_units=64,
    dense_units=8,
    num_heads=32,
    model_dim=64,
    dropout=0.1,
)

model_build_TFTattlstm_model.summary()

history_TFTattlstm_vmd = model_build_TFTattlstm_model.fit(
    X_train_vmd_scaled,
    y_train_vmd_scaled,
    validation_data=(X_test_vmd_scaled, y_test_vmd_scaled),
    epochs=EPOCHS,
    batch_size=BATCH_SIZE,
    verbose=1,
)

# Predict and inverse-transform
y_pred_TFTattlstm_vmd_scaled = model_build_TFTattlstm_model.predict(X_test_vmd_scaled)
# Flatten to 2D: (num_samples*time_steps, 1)
y_pred_flat = y_pred_TFTattlstm_vmd_scaled.reshape(-1, 1)
# Inverse transform
y_pred_TFTattlstm_vmd_true = scaler_y.inverse_transform(y_pred_flat)

# Optional: reshape back to (num_samples, time_steps)
y_pred_TFTattlstm_vmd_true = y_pred_TFTattlstm_vmd_true.reshape(
    y_pred_TFTattlstm_vmd_scaled.shape[0], y_pred_TFTattlstm_vmd_scaled.shape[1]
)
# =====================================================
# 8Ô∏è‚É£ Visualization
# =====================================================
plt.figure(figsize=(8, 4))
plt.plot(history_TFTattlstm_vmd.history["loss"], label="Train Loss")
plt.plot(history_TFTattlstm_vmd.history["val_loss"], label="Val Loss")
plt.title("Training & Validation Loss (TFT ATT-LSTM + VMD)")
plt.legend()
plt.grid(True)
plt.show()

plt.figure(figsize=(12, 5))
plt.plot(y_test_vmd_true, label="True OT", color="black", linewidth=1)
plt.plot(y_pred_TFTattlstm_vmd_true, label="Predicted OT", color="red", alpha=0.8)
plt.title("True vs Predicted OT (TFT ATT-LSTM + VMD)")
plt.xlabel("Time Steps")
plt.ylabel("OT Value")
plt.legend()
plt.grid(True)
plt.show()

plt.figure(figsize=(10, 4))
residuals = y_test_vmd_true.squeeze() - y_pred_TFTattlstm_vmd_true.squeeze()
plt.plot(residuals, color="purple")
plt.title("Residuals (True - Predicted)")
plt.grid(True)
plt.show()


res = y_test_vmd_true.squeeze() - y_pred_TFTattlstm_vmd_true.squeeze()
area_total_TFTattlstm_vmd = np.trapezoid(np.abs(res))
print("Total Area =", area_total_TFTattlstm_vmd)
area_positive_TFTattlstm_vmd = np.trapezoid(np.clip(res, 0, None))
area_negative_TFTattlstm_vmd = np.trapezoid(np.clip(res, None, 0))
print("Area + =", area_positive_TFTattlstm_vmd)
print("Area - =", area_negative_TFTattlstm_vmd)


model_build_TFTattlstm_model = build_TFTattlstm_model7(
    input_shape=(SEQ_LEN, X_train_vmd_scaled.shape[2]),
    lstm1_units=84,
    dense_units=32,
    num_heads=32,
    model_dim=128,
    dropout=0.1,
)

model_build_TFTattlstm_model.summary()

history_TFTattlstm_vmd = model_build_TFTattlstm_model.fit(
    X_train_vmd_scaled,
    y_train_vmd_scaled,
    validation_data=(X_test_vmd_scaled, y_test_vmd_scaled),
    epochs=EPOCHS,
    batch_size=BATCH_SIZE,
    verbose=1,
)

# Predict and inverse-transform
y_pred_TFTattlstm_vmd_scaled = model_build_TFTattlstm_model.predict(X_test_vmd_scaled)
# Flatten to 2D: (num_samples*time_steps, 1)
y_pred_flat = y_pred_TFTattlstm_vmd_scaled.reshape(-1, 1)
# Inverse transform
y_pred_TFTattlstm_vmd_true = scaler_y.inverse_transform(y_pred_flat)

# Optional: reshape back to (num_samples, time_steps)
y_pred_TFTattlstm_vmd_true = y_pred_TFTattlstm_vmd_true.reshape(
    y_pred_TFTattlstm_vmd_scaled.shape[0], y_pred_TFTattlstm_vmd_scaled.shape[1]
)
# =====================================================
# 8Ô∏è‚É£ Visualization
# =====================================================
plt.figure(figsize=(8, 4))
plt.plot(history_TFTattlstm_vmd.history["loss"], label="Train Loss")
plt.plot(history_TFTattlstm_vmd.history["val_loss"], label="Val Loss")
plt.title("Training & Validation Loss (TFT ATT-LSTM + VMD)")
plt.legend()
plt.grid(True)
plt.show()

plt.figure(figsize=(12, 5))
plt.plot(y_test_vmd_true, label="True OT", color="black", linewidth=1)
plt.plot(y_pred_TFTattlstm_vmd_true, label="Predicted OT", color="red", alpha=0.8)
plt.title("True vs Predicted OT (TFT ATT-LSTM + VMD)")
plt.xlabel("Time Steps")
plt.ylabel("OT Value")
plt.legend()
plt.grid(True)
plt.show()

plt.figure(figsize=(10, 4))
residuals = y_test_vmd_true.squeeze() - y_pred_TFTattlstm_vmd_true.squeeze()
plt.plot(residuals, color="purple")
plt.title("Residuals (True - Predicted)")
plt.grid(True)
plt.show()


res = y_test_vmd_true.squeeze() - y_pred_TFTattlstm_vmd_true.squeeze()
area_total_TFTattlstm_vmd = np.trapezoid(np.abs(res))
print("Total Area =", area_total_TFTattlstm_vmd)
area_positive_TFTattlstm_vmd = np.trapezoid(np.clip(res, 0, None))
area_negative_TFTattlstm_vmd = np.trapezoid(np.clip(res, None, 0))
print("Area + =", area_positive_TFTattlstm_vmd)
print("Area - =", area_negative_TFTattlstm_vmd)


model_build_TFTattlstm_model = build_TFTattlstm_model8(
    input_shape=(SEQ_LEN, X_train_vmd_scaled.shape[2]),
    lstm1_units=84,
    cnn_filters=64,
    cnn_kernel=12,
    dense_units=128,
    num_heads=32,
    model_dim=64,
    dropout=0.1,
)

model_build_TFTattlstm_model.summary()

history_TFTattlstm_vmd = model_build_TFTattlstm_model.fit(
    X_train_vmd_scaled,
    y_train_vmd_scaled,
    validation_data=(X_test_vmd_scaled, y_test_vmd_scaled),
    epochs=EPOCHS,
    batch_size=BATCH_SIZE,
    verbose=1,
)

# Predict and inverse-transform
y_pred_TFTattlstm_vmd_scaled = model_build_TFTattlstm_model.predict(X_test_vmd_scaled)
# Flatten to 2D: (num_samples*time_steps, 1)
y_pred_flat = y_pred_TFTattlstm_vmd_scaled.reshape(-1, 1)
# Inverse transform
y_pred_TFTattlstm_vmd_true = scaler_y.inverse_transform(y_pred_flat)

# Optional: reshape back to (num_samples, time_steps)
y_pred_TFTattlstm_vmd_true = y_pred_TFTattlstm_vmd_true.reshape(
    y_pred_TFTattlstm_vmd_scaled.shape[0], y_pred_TFTattlstm_vmd_scaled.shape[1]
)
# =====================================================
# 8Ô∏è‚É£ Visualization
# =====================================================
plt.figure(figsize=(8, 4))
plt.plot(history_TFTattlstm_vmd.history["loss"], label="Train Loss")
plt.plot(history_TFTattlstm_vmd.history["val_loss"], label="Val Loss")
plt.title("Training & Validation Loss (TFT ATT-LSTM + VMD)")
plt.legend()
plt.grid(True)
plt.show()

plt.figure(figsize=(12, 5))
plt.plot(y_test_vmd_true, label="True OT", color="black", linewidth=1)
plt.plot(y_pred_TFTattlstm_vmd_true, label="Predicted OT", color="red", alpha=0.8)
plt.title("True vs Predicted OT (TFT ATT-LSTM + VMD)")
plt.xlabel("Time Steps")
plt.ylabel("OT Value")
plt.legend()
plt.grid(True)
plt.show()

plt.figure(figsize=(10, 4))
residuals = y_test_vmd_true.squeeze() - y_pred_TFTattlstm_vmd_true.squeeze()
plt.plot(residuals, color="purple")
plt.title("Residuals (True - Predicted)")
plt.grid(True)
plt.show()


res = y_test_vmd_true.squeeze() - y_pred_TFTattlstm_vmd_true.squeeze()
area_total_TFTattlstm_vmd = np.trapezoid(np.abs(res))
print("Total Area =", area_total_TFTattlstm_vmd)
area_positive_TFTattlstm_vmd = np.trapezoid(np.clip(res, 0, None))
area_negative_TFTattlstm_vmd = np.trapezoid(np.clip(res, None, 0))
print("Area + =", area_positive_TFTattlstm_vmd)
print("Area - =", area_negative_TFTattlstm_vmd)


model_build_TFTattlstm_model = build_TFTattlstm_model9(
    input_shape=(SEQ_LEN, X_train_vmd_scaled.shape[2]),
    lstm1_units=84,
    cnn_filters=64,
    cnn_kernel=12,
    dense_units=128,
    num_heads=32,
    model_dim=128,
    dropout=0.2,
)

model_build_TFTattlstm_model.summary()

history_TFTattlstm_vmd = model_build_TFTattlstm_model.fit(
    X_train_vmd_scaled,
    y_train_vmd_scaled,
    validation_data=(X_test_vmd_scaled, y_test_vmd_scaled),
    epochs=EPOCHS,
    batch_size=BATCH_SIZE,
    verbose=1,
)

# Predict and inverse-transform
y_pred_TFTattlstm_vmd_scaled = model_build_TFTattlstm_model.predict(X_test_vmd_scaled)
# Flatten to 2D: (num_samples*time_steps, 1)
y_pred_flat = y_pred_TFTattlstm_vmd_scaled.reshape(-1, 1)
# Inverse transform
y_pred_TFTattlstm_vmd_true = scaler_y.inverse_transform(y_pred_flat)

# Optional: reshape back to (num_samples, time_steps)
y_pred_TFTattlstm_vmd_true = y_pred_TFTattlstm_vmd_true.reshape(
    y_pred_TFTattlstm_vmd_scaled.shape[0], y_pred_TFTattlstm_vmd_scaled.shape[1]
)
# =====================================================
# 8Ô∏è‚É£ Visualization
# =====================================================
plt.figure(figsize=(8, 4))
plt.plot(history_TFTattlstm_vmd.history["loss"], label="Train Loss")
plt.plot(history_TFTattlstm_vmd.history["val_loss"], label="Val Loss")
plt.title("Training & Validation Loss (TFT ATT-LSTM + VMD)")
plt.legend()
plt.grid(True)
plt.show()

plt.figure(figsize=(12, 5))
plt.plot(y_test_vmd_true, label="True OT", color="black", linewidth=1)
plt.plot(y_pred_TFTattlstm_vmd_true, label="Predicted OT", color="red", alpha=0.8)
plt.title("True vs Predicted OT (TFT ATT-LSTM + VMD)")
plt.xlabel("Time Steps")
plt.ylabel("OT Value")
plt.legend()
plt.grid(True)
plt.show()

plt.figure(figsize=(10, 4))
residuals = y_test_vmd_true.squeeze() - y_pred_TFTattlstm_vmd_true.squeeze()
plt.plot(residuals, color="purple")
plt.title("Residuals (True - Predicted)")
plt.grid(True)
plt.show()


res = y_test_vmd_true.squeeze() - y_pred_TFTattlstm_vmd_true.squeeze()
area_total_TFTattlstm_vmd = np.trapezoid(np.abs(res))
print("Total Area =", area_total_TFTattlstm_vmd)
area_positive_TFTattlstm_vmd = np.trapezoid(np.clip(res, 0, None))
area_negative_TFTattlstm_vmd = np.trapezoid(np.clip(res, None, 0))
print("Area + =", area_positive_TFTattlstm_vmd)
print("Area - =", area_negative_TFTattlstm_vmd)


(
    model_build_TFTattlstm_model,
    encoder_inputs,
    enc_out,
    bahdanau_att_enc,
    dec_out,
    bahdanau_att_dec,
    att_out,
) = build_TFTattlstm_model10(
    input_shape=(SEQ_LEN, X_train_vmd_scaled.shape[2]),
    lstm1_units=32,
    cnn_filters=128,
    cnn_kernel=12,
    dense_units=12,
    num_heads=32,
    model_dim=64,
    dropout=0.1,
)


model_build_TFTattlstm_model.summary()

history_TFTattlstm_vmd = model_build_TFTattlstm_model.fit(
    X_train_vmd_scaled,
    y_train_vmd_scaled,
    validation_data=(X_test_vmd_scaled, y_test_vmd_scaled),
    epochs=EPOCHS,
    batch_size=BATCH_SIZE,
    verbose=1,
)

# Predict and inverse-transform
y_pred_TFTattlstm_vmd_scaled = model_build_TFTattlstm_model.predict(X_test_vmd_scaled)
# Flatten to 2D: (num_samples*time_steps, 1)
y_pred_flat = y_pred_TFTattlstm_vmd_scaled.reshape(-1, 1)
# Inverse transform
y_pred_TFTattlstm_vmd_true = scaler_y.inverse_transform(y_pred_flat)

# Optional: reshape back to (num_samples, time_steps)
y_pred_TFTattlstm_vmd_true = y_pred_TFTattlstm_vmd_true.reshape(
    y_pred_TFTattlstm_vmd_scaled.shape[0], y_pred_TFTattlstm_vmd_scaled.shape[1]
)
# =====================================================
# 8Ô∏è‚É£ Visualization
# =====================================================
plt.figure(figsize=(8, 4))
plt.plot(history_TFTattlstm_vmd.history["loss"], label="Train Loss")
plt.plot(history_TFTattlstm_vmd.history["val_loss"], label="Val Loss")
plt.title("Training & Validation Loss (TFT ATT-LSTM + VMD)")
plt.legend()
plt.grid(True)
plt.show()

plt.figure(figsize=(12, 5))
plt.plot(y_test_vmd_true, label="True OT", color="black", linewidth=1)
plt.plot(y_pred_TFTattlstm_vmd_true, label="Predicted OT", color="red", alpha=0.8)
plt.title("True vs Predicted OT (TFT ATT-LSTM + VMD)")
plt.xlabel("Time Steps")
plt.ylabel("OT Value")
plt.legend()
plt.grid(True)
plt.show()

plt.figure(figsize=(10, 4))
residuals = y_test_vmd_true.squeeze() - y_pred_TFTattlstm_vmd_true.squeeze()
plt.plot(residuals, color="purple")
plt.title("Residuals (True - Predicted)")
plt.grid(True)
plt.show()


res = y_test_vmd_true.squeeze() - y_pred_TFTattlstm_vmd_true.squeeze()
area_total_TFTattlstm_vmd = np.trapezoid(np.abs(res))
print("Total Area =", area_total_TFTattlstm_vmd)
area_positive_TFTattlstm_vmd = np.trapezoid(np.clip(res, 0, None))
area_negative_TFTattlstm_vmd = np.trapezoid(np.clip(res, None, 0))
print("Area + =", area_positive_TFTattlstm_vmd)
print("Area - =", area_negative_TFTattlstm_vmd)

print(f"encoder_inputs:{encoder_inputs.shape}")
print(f"enc_out:{enc_out.shape}")
print(f"bahdanau_att_enc:{bahdanau_att_enc.shape}")
print(f"dec_out:{dec_out.shape}")
print(f"att_out:{att_out.shape}")


model_build_TFTattlstm_model = build_TFTattlstm_model11(
    input_shape=(SEQ_LEN, X_train_vmd_scaled.shape[2]),
    lstm1_units=84,
    cnn_filters=64,
    dense_units=32,
    num_heads=32,
    model_dim=64,
    dropout=0.1,
    feature_extractor="inception",
)

model_build_TFTattlstm_model.summary()

history_TFTattlstm_vmd = model_build_TFTattlstm_model.fit(
    X_train_vmd_scaled,
    y_train_vmd_scaled,
    validation_data=(X_test_vmd_scaled, y_test_vmd_scaled),
    epochs=EPOCHS,
    batch_size=BATCH_SIZE,
    verbose=1,
)

# Predict and inverse-transform
y_pred_TFTattlstm_vmd_scaled = model_build_TFTattlstm_model.predict(X_test_vmd_scaled)
# Flatten to 2D: (num_samples*time_steps, 1)
y_pred_flat = y_pred_TFTattlstm_vmd_scaled.reshape(-1, 1)
# Inverse transform
y_pred_TFTattlstm_vmd_true = scaler_y.inverse_transform(y_pred_flat)

# Optional: reshape back to (num_samples, time_steps)
y_pred_TFTattlstm_vmd_true = y_pred_TFTattlstm_vmd_true.reshape(
    y_pred_TFTattlstm_vmd_scaled.shape[0], y_pred_TFTattlstm_vmd_scaled.shape[1]
)
# =====================================================
# 8Ô∏è‚É£ Visualization
# =====================================================
plt.figure(figsize=(8, 4))
plt.plot(history_TFTattlstm_vmd.history["loss"], label="Train Loss")
plt.plot(history_TFTattlstm_vmd.history["val_loss"], label="Val Loss")
plt.title("Training & Validation Loss (TFT ATT-LSTM + VMD)")
plt.legend()
plt.grid(True)
plt.show()

plt.figure(figsize=(12, 5))
plt.plot(y_test_vmd_true, label="True OT", color="black", linewidth=1)
plt.plot(y_pred_TFTattlstm_vmd_true, label="Predicted OT", color="red", alpha=0.8)
plt.title("True vs Predicted OT (TFT ATT-LSTM + VMD)")
plt.xlabel("Time Steps")
plt.ylabel("OT Value")
plt.legend()
plt.grid(True)
plt.show()

plt.figure(figsize=(10, 4))
residuals = y_test_vmd_true.squeeze() - y_pred_TFTattlstm_vmd_true.squeeze()
plt.plot(residuals, color="purple")
plt.title("Residuals (True - Predicted)")
plt.grid(True)
plt.show()


res = y_test_vmd_true.squeeze() - y_pred_TFTattlstm_vmd_true.squeeze()
area_total_TFTattlstm_vmd = np.trapezoid(np.abs(res))
print("Total Area =", area_total_TFTattlstm_vmd)
area_positive_TFTattlstm_vmd = np.trapezoid(np.clip(res, 0, None))
area_negative_TFTattlstm_vmd = np.trapezoid(np.clip(res, None, 0))
print("Area + =", area_positive_TFTattlstm_vmd)
print("Area - =", area_negative_TFTattlstm_vmd)


(
    model_build_TFTattlstm_model,
    encoder_inputs,
    enc_out,
    dec_out,
    att_out,
) = build_TFTattlstm_model12(
    input_shape=(SEQ_LEN, X_train_vmd_scaled.shape[2]),
    lstm1_units=80,
    cnn_filters=8,
    cnn_kernel=128,
    dense_units=32,
    model_dim=64,
    dropout=0.1,
)


model_build_TFTattlstm_model.summary()

history_TFTattlstm_vmd = model_build_TFTattlstm_model.fit(
    X_train_vmd_scaled,
    y_train_vmd_scaled,
    validation_data=(X_test_vmd_scaled, y_test_vmd_scaled),
    epochs=EPOCHS,
    batch_size=BATCH_SIZE,
    verbose=1,
)

# Predict and inverse-transform
y_pred_TFTattlstm_vmd_scaled = model_build_TFTattlstm_model.predict(X_test_vmd_scaled)
# Flatten to 2D: (num_samples*time_steps, 1)
y_pred_flat = y_pred_TFTattlstm_vmd_scaled.reshape(-1, 1)
# Inverse transform
y_pred_TFTattlstm_vmd_true = scaler_y.inverse_transform(y_pred_flat)

# Optional: reshape back to (num_samples, time_steps)
y_pred_TFTattlstm_vmd_true = y_pred_TFTattlstm_vmd_true.reshape(
    y_pred_TFTattlstm_vmd_scaled.shape[0], y_pred_TFTattlstm_vmd_scaled.shape[1]
)
# =====================================================
# 8Ô∏è‚É£ Visualization
# =====================================================
plt.figure(figsize=(8, 4))
plt.plot(history_TFTattlstm_vmd.history["loss"], label="Train Loss")
plt.plot(history_TFTattlstm_vmd.history["val_loss"], label="Val Loss")
plt.title("Training & Validation Loss (TFT ATT-LSTM + VMD)")
plt.legend()
plt.grid(True)
plt.show()

plt.figure(figsize=(12, 5))
plt.plot(y_test_vmd_true, label="True OT", color="black", linewidth=1)
plt.plot(y_pred_TFTattlstm_vmd_true, label="Predicted OT", color="red", alpha=0.8)
plt.title("True vs Predicted OT (TFT ATT-LSTM + VMD)")
plt.xlabel("Time Steps")
plt.ylabel("OT Value")
plt.legend()
plt.grid(True)
plt.show()

plt.figure(figsize=(10, 4))
residuals = y_test_vmd_true.squeeze() - y_pred_TFTattlstm_vmd_true.squeeze()
plt.plot(residuals, color="purple")
plt.title("Residuals (True - Predicted)")
plt.grid(True)
plt.show()


res = y_test_vmd_true.squeeze() - y_pred_TFTattlstm_vmd_true.squeeze()
area_total_TFTattlstm_vmd = np.trapezoid(np.abs(res))
print("Total Area =", area_total_TFTattlstm_vmd)
area_positive_TFTattlstm_vmd = np.trapezoid(np.clip(res, 0, None))
area_negative_TFTattlstm_vmd = np.trapezoid(np.clip(res, None, 0))
print("Area + =", area_positive_TFTattlstm_vmd)
print("Area - =", area_negative_TFTattlstm_vmd)

print(f"encoder_inputs:{encoder_inputs.shape}")
print(f"enc_out:{enc_out.shape}")
print(f"dec_out:{dec_out.shape}")
print(f"att_out:{att_out.shape}")


(   model_build_TFTattlstm_model,
    grad2,
    block1,
    block2,
    att_out,
) = build_TFTattlstm_model13(
    input_shape=(SEQ_LEN, X_train_vmd_scaled.shape[2]),
    lstm1_units=40,
    cnn_filters=44,
    cnn_kernel=16,
    dense_units=16,
    model_dim=64,
    dropout=0.2,
)


model_build_TFTattlstm_model.summary()

history_TFTattlstm_vmd = model_build_TFTattlstm_model.fit(
    X_train_vmd_scaled,
    y_train_vmd_scaled,
    validation_data=(X_test_vmd_scaled, y_test_vmd_scaled),
    epochs=EPOCHS,
    batch_size=BATCH_SIZE,
    verbose=1,
)

# Predict and inverse-transform
y_pred_TFTattlstm_vmd_scaled = model_build_TFTattlstm_model.predict(X_test_vmd_scaled)
# Flatten to 2D: (num_samples*time_steps, 1)
y_pred_flat = y_pred_TFTattlstm_vmd_scaled.reshape(-1, 1)
# Inverse transform
y_pred_TFTattlstm_vmd_true = scaler_y.inverse_transform(y_pred_flat)

# Optional: reshape back to (num_samples, time_steps)
y_pred_TFTattlstm_vmd_true = y_pred_TFTattlstm_vmd_true.reshape(
    y_pred_TFTattlstm_vmd_scaled.shape[0], y_pred_TFTattlstm_vmd_scaled.shape[1]
)
# =====================================================
# 8Ô∏è‚É£ Visualization
# =====================================================
plt.figure(figsize=(8, 4))
plt.plot(history_TFTattlstm_vmd.history["loss"], label="Train Loss")
plt.plot(history_TFTattlstm_vmd.history["val_loss"], label="Val Loss")
plt.title("Training & Validation Loss (TFT ATT-LSTM + VMD)")
plt.legend()
plt.grid(True)
plt.show()

plt.figure(figsize=(12, 5))
plt.plot(y_test_vmd_true, label="True OT", color="black", linewidth=1)
plt.plot(y_pred_TFTattlstm_vmd_true, label="Predicted OT", color="red", alpha=0.8)
plt.title("True vs Predicted OT (TFT ATT-LSTM + VMD)")
plt.xlabel("Time Steps")
plt.ylabel("OT Value")
plt.legend()
plt.grid(True)
plt.show()

plt.figure(figsize=(10, 4))
residuals = y_test_vmd_true.squeeze() - y_pred_TFTattlstm_vmd_true.squeeze()
plt.plot(residuals, color="purple")
plt.title("Residuals (True - Predicted)")
plt.grid(True)
plt.show()


res = y_test_vmd_true.squeeze() - y_pred_TFTattlstm_vmd_true.squeeze()
area_total_TFTattlstm_vmd = np.trapezoid(np.abs(res))
print("Total Area =", area_total_TFTattlstm_vmd)
area_positive_TFTattlstm_vmd = np.trapezoid(np.clip(res, 0, None))
area_negative_TFTattlstm_vmd = np.trapezoid(np.clip(res, None, 0))
print("Area + =", area_positive_TFTattlstm_vmd)
print("Area - =", area_negative_TFTattlstm_vmd)






model_build_attlstm_model = build_attlstm_model(
    input_shape=(SEQ_LEN, X_train_simple.shape[2]),
    lstm1_units=122,
    lstm2_units=122,
    dense_units=64,
)

model_build_attlstm_model.summary()

history_attlstm_simple = model_build_attlstm_model.fit(
    X_train_simple,
    y_train_simple,
    validation_data=(X_test_simple, y_test_simple),
    epochs=EPOCHS,
    batch_size=BATCH_SIZE,
    verbose=1,
)

# Predict (inverse-transform from original OT scaling)
y_pred_attlstm_simple_ga_scaled = model_build_attlstm_model.predict(X_test_simple)
y_pred_attlstm_simple_true = scaler_y.inverse_transform(y_pred_attlstm_simple_ga_scaled)

# =====================================================
# 8Ô∏è‚É£ Visualization
# =====================================================
plt.figure(figsize=(8, 4))
plt.plot(history_attlstm_simple.history["loss"], label="Train Loss")
plt.plot(history_attlstm_simple.history["val_loss"], label="Val Loss")
plt.title("Training & Validation Loss (ATT-LSTM + Simple)")
plt.legend()
plt.grid(True)
plt.show()

plt.figure(figsize=(12, 5))
plt.plot(y_test_simple_true, label="True OT", color="black", linewidth=1)
plt.plot(y_pred_attlstm_simple_true, label="Predicted OT", color="red", alpha=0.8)
plt.title("True vs Predicted OT (Optimized ATT-LSTM + Simple)")
plt.xlabel("Time Steps")
plt.ylabel("OT Value")
plt.legend()
plt.grid(True)
plt.show()

plt.figure(figsize=(10, 4))
residuals = y_test_simple_true.squeeze() - y_pred_attlstm_simple_true.squeeze()
plt.plot(residuals, color="purple")
plt.title("Residuals (True - Predicted)")
plt.grid(True)
plt.show()

res = y_test_simple_true.squeeze() - y_pred_attlstm_simple_true.squeeze()
area_total_attlstm_simple = np.trapezoid(np.abs(res))
print("Total Area =", area_total_attlstm_simple)
area_positive_attlstm_simple = np.trapezoid(np.clip(res, 0, None))
area_negative_attlstm_simple = np.trapezoid(np.clip(res, None, 0))
print("Area + =", area_positive_attlstm_simple)
print("Area - =", area_negative_attlstm_simple)





# ---------------------------
# 5. Build Bidirectional_LSTM model
# ---------------------------
input_shape = (SEQ_LEN, X_train_simple.shape[2])
inputs = Input(shape=input_shape)
x = Bidirectional(LSTM(100, return_sequences=True))(inputs)
x = Dropout(0.2)(x)
x = LSTM(100)(x)
x = Dropout(0.2)(x)
outputs = Dense(1)(x)

Bidirectional_lstm = Model(inputs, outputs)
Bidirectional_lstm.compile(optimizer="adam", loss="mse", metrics=["mae"])

Bidirectional_lstm.summary()

# Early stopping
early_stop = EarlyStopping(monitor="val_loss", patience=10, restore_best_weights=True)

# Train model
history_Bidirectional_lstm_simple = Bidirectional_lstm.fit(
    X_train_simple,
    y_train_simple,
    epochs=EPOCHS,
    batch_size=BATCH_SIZE,
    validation_data=(X_test_simple, y_test_simple),
    callbacks=[early_stop],
    verbose=1,
)

# Plot training history
plt.figure(figsize=(8, 4))
plt.plot(history_Bidirectional_lstm_simple.history["loss"], label="Training Loss")
plt.plot(history_Bidirectional_lstm_simple.history["val_loss"], label="Validation Loss")
plt.xlabel("Epochs")
plt.ylabel("MSE Loss")
plt.title("Bidirectional LSTM Training Performance")
plt.legend()
plt.grid(True)
plt.show()

# Make predictions
y_pred_scaled_Bidirectional_lstm = Bidirectional_lstm.predict(X_test_simple)
y_pred_Bidirectional_lstm_simple_true = scaler_y.inverse_transform(
    y_pred_scaled_Bidirectional_lstm.reshape(-1, 1)
).flatten()

# Plot predictions vs true values
plt.figure(figsize=(12, 5))
plt.plot(y_test_simple_true, label="True OT", color="blue")
plt.plot(y_pred_Bidirectional_lstm_simple_true, label="Predicted OT", color="green")
plt.xlabel("Time Steps")
plt.ylabel("Oil Temperature")
plt.title("Advanced LSTM Predictions vs True Values")
plt.legend()
plt.grid(True)
plt.show()

plt.figure(figsize=(10, 4))
res = y_pred_Bidirectional_lstm_simple_true.squeeze() - y_test_simple_true.squeeze()
plt.plot(res, color="purple")
plt.title("Residuals (True - Pred)")
plt.grid(True)
plt.show()

res = y_test_simple_true.squeeze() - y_pred_Bidirectional_lstm_simple_true.squeeze()
area_total_Bidirectional_lstm_simple = np.trapezoid(np.abs(res))
print("Total Area =", area_total_Bidirectional_lstm_simple)
area_positive_Bidirectional_lstm_simple = np.trapezoid(np.clip(res, 0, None))
area_negative_Bidirectional_lstm_simple = np.trapezoid(np.clip(res, None, 0))
print("Area + =", area_positive_Bidirectional_lstm_simple)
print("Area - =", area_negative_Bidirectional_lstm_simple)





# ---------------------------
# 5. Build LSTM model
# ---------------------------
SEQ_LEN = X_train_vmd_scaled.shape[1]
N_FEATURES = X_train_vmd_scaled.shape[2]

inputs = Input(shape=(SEQ_LEN, N_FEATURES))

x = LSTM(128, return_sequences=True)(inputs)
x = Dropout(0.2)(x)
x = LSTM(128)(x)
x = Dropout(0.2)(x)
outputs = Dense(1)(x)

model_lstm_model = Model(inputs, outputs)
model_lstm_model.compile(optimizer="adam", loss="mse", metrics=["mae"])

model_lstm_model.summary()

# ---------------------------
# 6. Train
# ---------------------------
history_lstm_vmd = model_lstm_model.fit(
    X_train_vmd_scaled,
    y_train_vmd_scaled,
    validation_data=(X_test_vmd_scaled, y_test_vmd_scaled),
    epochs=EPOCHS,
    batch_size=BATCH_SIZE,
    verbose=1,
)

# ---------------------------
# 7. Predict & inverse-transform
# ---------------------------
y_pred_lstm_vmd_scaled = model_lstm_model.predict(X_test_vmd_scaled)
y_pred_lstm_vmd_true = scaler_y.inverse_transform(y_pred_lstm_vmd_scaled).flatten()

# ---------------------------
# 9. Plots
# ---------------------------
plt.figure(figsize=(8, 4))
plt.plot(history_lstm_vmd.history["loss"], label="train loss")
plt.plot(history_lstm_vmd.history["val_loss"], label="val loss")
plt.xlabel("epoch")
plt.ylabel("mse")
plt.legend()
plt.grid(True)
plt.title("Train / Val Loss")
plt.show()

plt.figure(figsize=(12, 5))
plt.plot(y_test_vmd_true, label="True OT", color="black", linewidth=1)
plt.plot(y_pred_lstm_vmd_true, label="Predicted OT", color="red", alpha=0.8)
plt.xlabel("time steps (test)")
plt.ylabel("OT")
plt.title("True vs Predicted OT (VMD -> LSTM)")
plt.legend()
plt.grid(True)
plt.show()

plt.figure(figsize=(10, 4))
res = y_test_vmd_true - y_pred_lstm_vmd_true
plt.plot(res, color="purple")
plt.title("Residuals (True - Pred)")
plt.grid(True)
plt.show()

res = y_test_vmd_true.squeeze() - y_pred_lstm_vmd_true
area_total_lstm_vmd = np.trapezoid(np.abs(res))
print("Total Area =", area_total_lstm_vmd)
area_positive_lstm_vmd = np.trapezoid(np.clip(res, 0, None))
area_negative_lstm_vmd = np.trapezoid(np.clip(res, None, 0))
print("Area + =", area_positive_lstm_vmd)
print("Area - =", area_negative_lstm_vmd)





import numpy as np
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score


def compute_metrics(y_true, y_pred):
    min_len = min(len(y_true), len(y_pred))
    y_true, y_pred = y_true[:min_len], y_pred[:min_len]
    mse = mean_squared_error(y_true, y_pred)
    rmse = np.sqrt(mse)
    mae = mean_absolute_error(y_true, y_pred)
    r2 = r2_score(y_true, y_pred)
    return mse, rmse, mae, r2


# Compute metrics
mse_Attlstm_vmd, rmse_Attlstm_vmd, mae_Attlstm_vmd, r2_attlstm_vmd = compute_metrics(
    y_pred_attlstm_vmd_true, y_test_vmd_true
)
(
    mse_TAttlstm_vmd,
    rmse_TAttlstm_vmd,
    mae_TAttlstm_vmd,
    r2_Tattlstm_vmd,
) = compute_metrics(y_pred_Tattlstm_vmd_true, y_test_vmd_true)
(
    mse_TFTAttlstm_vmd,
    rmse_TFTAttlstm_vmd,
    mae_TFTAttlstm_vmd,
    r2_TFTattlstm_vmd,
) = compute_metrics(y_pred_TFTattlstm_vmd_true, y_test_vmd_true)
(
    mse_Lstm_Bidirectional_simple,
    rmse_Lstm_Bidirectional_simple,
    mae_Lstm_Bidirectional_simple,
    r2_Lstm_Bidirectional_simple,
) = compute_metrics(y_pred_Bidirectional_lstm_simple_true, y_test_simple_true)
(
    mse_Attlstm_simple,
    rmse_Attlstm_simple,
    mae_Attlstm_simple,
    r2_attlstm_simple,
) = compute_metrics(y_pred_attlstm_simple_true, y_test_simple_true)
mse_Lstm_vmd, rmse_Lstm_vmd, mae_Lstm_vmd, r2_Lstm_vmd = compute_metrics(
    y_pred_lstm_vmd_true, y_test_vmd_true
)

# Print comparison
print("üìà Model Performance Comparison")
print(
    f"ATT-LSTM-VMD: MSE={mse_Attlstm_vmd:.4f}, RMSE={rmse_Attlstm_vmd:.4f}, MAE={mae_Attlstm_vmd:.4f}, R¬≤={r2_attlstm_vmd:.4f}, total_area={area_total_attlstm_vmd:.4f}"
)
print(
    f"TATT-LSTM-VMD: MSE={mse_TAttlstm_vmd:.4f}, RMSE={rmse_TAttlstm_vmd:.4f}, MAE={mae_TAttlstm_vmd:.4f}, R¬≤={r2_Tattlstm_vmd:.4f}, total_area={area_total_Tattlstm_vmd:.4f}"
)
print(
    f"TFTATT-LSTM-VMD: MSE={mse_TFTAttlstm_vmd:.4f}, RMSE={rmse_TFTAttlstm_vmd:.4f}, MAE={mae_TFTAttlstm_vmd:.4f}, R¬≤={r2_TFTattlstm_vmd:.4f}, total_area={area_total_TFTattlstm_vmd:.4f}"
)
print(
    f"Bidirectional_Lstm_Simple: MSE={mse_Lstm_Bidirectional_simple:.4f}, RMSE={rmse_Lstm_Bidirectional_simple:.4f}, MAE={mae_Lstm_Bidirectional_simple:.4f}, R¬≤={r2_Lstm_Bidirectional_simple:.4f}, total_area={area_total_Bidirectional_lstm_simple:.4f}"
)
print(
    f"Attlstm_Simple: MSE={mse_Attlstm_simple:.4f}, RMSE={rmse_Attlstm_simple:.4f}, MAE={mae_Attlstm_simple:.4f}, R¬≤={r2_attlstm_simple:.4f}, total_area={area_total_attlstm_simple:.4f}"
)
print(
    f"Lstm_vmd: MSE={mse_Lstm_vmd:.4f}, RMSE={rmse_Lstm_vmd:.4f}, MAE={mae_Lstm_vmd:.4f}, R¬≤={r2_Lstm_vmd:.4f}, total_area={area_total_lstm_vmd:.4f}"
)


diff = y_train_simple_scaled - y_train_vmd_scaled
plt.figure(figsize=(10, 4))
plt.plot(diff, color="orange")
plt.title("Difference: y_train_simple vs y_train_vmd")
plt.xlabel("Time steps")
plt.ylabel("Temperature difference")
plt.grid(True)
plt.show()

y_test_vmd_true = scaler_y.inverse_transform(y_test_vmd_scaled)
y_test_simple_true = scaler_y.inverse_transform(y_test_simple_scaled)
diff = y_test_simple_true - y_test_vmd_true
plt.figure(figsize=(10, 4))
plt.plot(diff, color="orange")
plt.title("Difference: VMD-test-true vs Simple-test-true of OT")
plt.xlabel("Time steps")
plt.ylabel("Temperature difference")
plt.grid(True)
plt.show()
